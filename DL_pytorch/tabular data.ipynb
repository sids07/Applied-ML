{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train1.csv\",usecols = ['SalePrice','MSSubClass','MSZoning','LotFrontage','LotArea','Street','YearBuilt','LotShape','1stFlrSF','2ndFlrSF']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>2003</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1976</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2001</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1915</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  YearBuilt  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg       2003   \n",
       "1          20       RL         80.0     9600   Pave      Reg       1976   \n",
       "2          60       RL         68.0    11250   Pave      IR1       2001   \n",
       "3          70       RL         60.0     9550   Pave      IR1       1915   \n",
       "4          60       RL         84.0    14260   Pave      IR1       2000   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  SalePrice  \n",
       "0       856       854     208500  \n",
       "1      1262         0     181500  \n",
       "2       920       866     223500  \n",
       "3       961       756     140000  \n",
       "4      1145      1053     250000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1201 entries, 0 to 1459\n",
      "Data columns (total 10 columns):\n",
      "MSSubClass     1201 non-null int64\n",
      "MSZoning       1201 non-null object\n",
      "LotFrontage    1201 non-null float64\n",
      "LotArea        1201 non-null int64\n",
      "Street         1201 non-null object\n",
      "LotShape       1201 non-null object\n",
      "YearBuilt      1201 non-null int64\n",
      "1stFlrSF       1201 non-null int64\n",
      "2ndFlrSF       1201 non-null int64\n",
      "SalePrice      1201 non-null int64\n",
      "dtypes: float64(1), int64(6), object(3)\n",
      "memory usage: 103.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pytorch --> Tabular\n",
    "\n",
    "1. Categorical Features -- Embedding Layers\n",
    "2. Continous \n",
    "\n",
    "\n",
    "1. Categorical Features--\n",
    "\n",
    "a) Label Encoding\n",
    "\n",
    "b) take all categorical features --- convert into numpy and then torch(tensors)\n",
    "\n",
    "c) Lets take all the continous values\n",
    "\n",
    "d) convert continous into numpy and then tensor\n",
    "\n",
    "c) Embedding Layers(only for categorical features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name MSSubClass and unique value:15\n",
      "Column Name MSZoning and unique value:5\n",
      "Column Name LotFrontage and unique value:110\n",
      "Column Name LotArea and unique value:869\n",
      "Column Name Street and unique value:2\n",
      "Column Name LotShape and unique value:4\n",
      "Column Name YearBuilt and unique value:112\n",
      "Column Name 1stFlrSF and unique value:678\n",
      "Column Name 2ndFlrSF and unique value:368\n",
      "Column Name SalePrice and unique value:597\n"
     ]
    }
   ],
   "source": [
    "for i in data.columns:\n",
    "    print(\"Column Name {} and unique value:{}\".format(i,len(data[i].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "today_year = datetime.datetime.now().year\n",
    "today_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Total_years']= today_year-data['YearBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Total_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>2003</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1976</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2001</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1915</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  YearBuilt  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg       2003   \n",
       "1          20       RL         80.0     9600   Pave      Reg       1976   \n",
       "2          60       RL         68.0    11250   Pave      IR1       2001   \n",
       "3          70       RL         60.0     9550   Pave      IR1       1915   \n",
       "4          60       RL         84.0    14260   Pave      IR1       2000   \n",
       "\n",
       "   1stFlrSF  2ndFlrSF  SalePrice  Total_years  \n",
       "0       856       854     208500           17  \n",
       "1      1262         0     181500           44  \n",
       "2       920       866     223500           19  \n",
       "3       961       756     140000          105  \n",
       "4      1145      1053     250000           20  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('YearBuilt',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Total_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  1stFlrSF  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg       856   \n",
       "1          20       RL         80.0     9600   Pave      Reg      1262   \n",
       "2          60       RL         68.0    11250   Pave      IR1       920   \n",
       "3          70       RL         60.0     9550   Pave      IR1       961   \n",
       "4          60       RL         84.0    14260   Pave      IR1      1145   \n",
       "\n",
       "   2ndFlrSF  SalePrice  Total_years  \n",
       "0       854     208500           17  \n",
       "1         0     181500           44  \n",
       "2       866     223500           19  \n",
       "3       756     140000          105  \n",
       "4      1053     250000           20  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_class = ['MSSubClass','MSZoning','Street','LotShape']\n",
    "out_feature = 'SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 60,  20,  70,  50, 190,  45,  90, 120,  30,  80, 160,  75, 180,\n",
       "        40,  85])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['MSSubClass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl_encoder={}\n",
    "for features in categorical_class:\n",
    "    \n",
    "    lbl_encoder[features] = LabelEncoder()\n",
    "    data[features]=lbl_encoder[features].fit_transform(data[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Total_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>208500</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>223500</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>140000</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>250000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  1stFlrSF  \\\n",
       "0           5         3         65.0     8450       1         3       856   \n",
       "1           0         3         80.0     9600       1         3      1262   \n",
       "2           5         3         68.0    11250       1         0       920   \n",
       "3           6         3         60.0     9550       1         0       961   \n",
       "4           5         3         84.0    14260       1         0      1145   \n",
       "\n",
       "   2ndFlrSF  SalePrice  Total_years  \n",
       "0       854     208500           17  \n",
       "1         0     181500           44  \n",
       "2       866     223500           19  \n",
       "3       756     140000          105  \n",
       "4      1053     250000           20  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3, 1, 3],\n",
       "       [0, 3, 1, 3],\n",
       "       [5, 3, 1, 0],\n",
       "       ...,\n",
       "       [6, 3, 1, 3],\n",
       "       [0, 3, 1, 3],\n",
       "       [0, 3, 1, 3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "cat_features = np.stack([data['MSSubClass'],data['MSZoning'],data['Street'],data['LotShape']],1)\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [5, 3, 1, 0],\n",
       "        ...,\n",
       "        [6, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [0, 3, 1, 3]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to tensor\n",
    "import torch\n",
    "cat_features=torch.tensor(cat_features,dtype = torch.int64)\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create continous variable\n",
    "\n",
    "cont_features = []\n",
    "\n",
    "for i in data.columns:\n",
    "    if i in ['MSSubClass','MSZoning','Street','LotShape','SalePrice']:\n",
    "        pass\n",
    "    else:\n",
    "        cont_features.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage', 'LotArea', '1stFlrSF', '2ndFlrSF', 'Total_years']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   65.,  8450.,   856.,   854.,    17.],\n",
       "        [   80.,  9600.,  1262.,     0.,    44.],\n",
       "        [   68., 11250.,   920.,   866.,    19.],\n",
       "        ...,\n",
       "        [   66.,  9042.,  1188.,  1152.,    79.],\n",
       "        [   68.,  9717.,  1078.,     0.,    70.],\n",
       "        [   75.,  9937.,  1256.,     0.,    55.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_value = np.stack ([data[i].values for i in cont_features],axis=1)\n",
    "cont_value = torch.tensor(cont_value,dtype = torch.float32)\n",
    "cont_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[208500.],\n",
       "        [181500.],\n",
       "        [223500.],\n",
       "        ...,\n",
       "        [266500.],\n",
       "        [142125.],\n",
       "        [147500.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor(data['SalePrice'].values,dtype=torch.float32).reshape(-1,1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1201, 4]), torch.Size([1201, 5]), torch.Size([1201, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features.shape,cont_value.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeding size for categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  0,  6,  4, 14,  3, 10, 11,  1,  8, 12,  7, 13,  2,  9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['MSSubClass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 5, 2, 4]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims = [len(data[features].unique()) for features in ['MSSubClass','MSZoning','Street','LotShape']]\n",
    "cat_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15, 8), (5, 3), (2, 1), (4, 2)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### output dimension should be set based on input i.e. min(50,feature_dim/2) just a thumb rule from fastai blog\n",
    "\n",
    "embedding_dim = [(x,min(50,(x+1)//2)) for x in cat_dims]\n",
    "embedding_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(15, 8)\n",
       "  (1): Embedding(5, 3)\n",
       "  (2): Embedding(2, 1)\n",
       "  (3): Embedding(4, 2)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_representation = nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dim])\n",
    "embed_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [5, 3, 1, 0],\n",
       "        ...,\n",
       "        [6, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [0, 3, 1, 3]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 3, 1, 3],\n",
       "        [0, 3, 1, 3],\n",
       "        [5, 3, 1, 0],\n",
       "        [6, 3, 1, 0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_1 = cat_features[:4]\n",
    "cat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',500)\n",
    "\n",
    "embed_value=[]\n",
    "for i,e in enumerate(embed_representation):\n",
    "    embed_value.append(e(cat_1[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1.9814, -0.5713,  0.8799,  1.1903,  0.2759,  0.2627,  0.7341, -0.2121],\n",
       "         [ 1.4605, -0.1467,  1.0732,  0.1677, -0.0200, -0.2191, -1.0024, -1.6029],\n",
       "         [-1.9814, -0.5713,  0.8799,  1.1903,  0.2759,  0.2627,  0.7341, -0.2121],\n",
       "         [-0.1172,  0.3314, -2.3255,  0.0274, -0.2469, -0.4478, -1.2908,  1.5653]],\n",
       "        grad_fn=<EmbeddingBackward>), tensor([[1.2226, 1.3562, 0.6092],\n",
       "         [1.2226, 1.3562, 0.6092],\n",
       "         [1.2226, 1.3562, 0.6092],\n",
       "         [1.2226, 1.3562, 0.6092]], grad_fn=<EmbeddingBackward>), tensor([[0.9612],\n",
       "         [0.9612],\n",
       "         [0.9612],\n",
       "         [0.9612]], grad_fn=<EmbeddingBackward>), tensor([[-1.0268, -2.0485],\n",
       "         [-1.0268, -2.0485],\n",
       "         [ 0.0806, -0.5289],\n",
       "         [ 0.0806, -0.5289]], grad_fn=<EmbeddingBackward>)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can clearly see that first column of every row is converted to 8 dim and 2nd to 3 and 3rd to 1 and 4th to 2\n",
    "\n",
    "Now we must bring them to systematic order as it was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9814, -0.5713,  0.8799,  1.1903,  0.2759,  0.2627,  0.7341, -0.2121,\n",
       "          1.2226,  1.3562,  0.6092,  0.9612, -1.0268, -2.0485],\n",
       "        [ 1.4605, -0.1467,  1.0732,  0.1677, -0.0200, -0.2191, -1.0024, -1.6029,\n",
       "          1.2226,  1.3562,  0.6092,  0.9612, -1.0268, -2.0485],\n",
       "        [-1.9814, -0.5713,  0.8799,  1.1903,  0.2759,  0.2627,  0.7341, -0.2121,\n",
       "          1.2226,  1.3562,  0.6092,  0.9612,  0.0806, -0.5289],\n",
       "        [-0.1172,  0.3314, -2.3255,  0.0274, -0.2469, -0.4478, -1.2908,  1.5653,\n",
       "          1.2226,  1.3562,  0.6092,  0.9612,  0.0806, -0.5289]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.cat(embed_value,axis=1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout= nn.Dropout(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.0000,  0.0000,  0.0000,  0.4599,  0.4379,  1.2236, -0.3534,\n",
       "          0.0000,  2.2603,  1.0153,  0.0000, -1.7113, -3.4142],\n",
       "        [ 0.0000, -0.2445,  1.7887,  0.0000, -0.0000, -0.3652, -1.6707, -0.0000,\n",
       "          0.0000,  2.2603,  0.0000,  1.6021, -0.0000, -3.4142],\n",
       "        [-3.3024, -0.9521,  1.4665,  0.0000,  0.0000,  0.4379,  0.0000, -0.3534,\n",
       "          0.0000,  2.2603,  1.0153,  0.0000,  0.1344, -0.8815],\n",
       "        [-0.1953,  0.5523, -3.8758,  0.0000, -0.4115, -0.7463, -0.0000,  2.6089,\n",
       "          0.0000,  2.2603,  0.0000,  1.6021,  0.0000, -0.8815]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embed = dropout(z)\n",
    "final_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self,embedding_dim,n_cont,out_sz,layers,p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(int,out) for int,out in embedding_dim])\n",
    "        self.embed_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((out for inp,out in embedding_dim))\n",
    "        n_in = n_emb + n_cont\n",
    "        #n_emb will be len of above final_embed\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i))\n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        \n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "        \n",
    "    def forward(self,x_cat,x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings,axis=1)\n",
    "        x = self.embed_drop(x)\n",
    "        \n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x,x_cont],axis=1)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardNN(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(15, 8)\n",
       "    (1): Embedding(5, 3)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(4, 2)\n",
       "  )\n",
       "  (embed_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=19, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(100)\n",
    "model = FeedForwardNN(embedding_dim,len(cont_features),1,[100,50],p=0.4)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = data.shape[0]-1\n",
    "test_size =int( batch_size*0.15)\n",
    "\n",
    "train_cat = cat_features[:batch_size-test_size]\n",
    "test_cat = cat_features[batch_size-test_size:]\n",
    "\n",
    "train_cont = cont_value[:batch_size-test_size]\n",
    "test_cont = cont_value[batch_size-test_size:]\n",
    "\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 10 with Loss :200493.9375\n",
      "Epochs 20 with Loss :200489.78125\n",
      "Epochs 30 with Loss :200483.640625\n",
      "Epochs 40 with Loss :200474.859375\n",
      "Epochs 50 with Loss :200463.0625\n",
      "Epochs 60 with Loss :200448.828125\n",
      "Epochs 70 with Loss :200431.015625\n",
      "Epochs 80 with Loss :200410.1875\n",
      "Epochs 90 with Loss :200386.328125\n",
      "Epochs 100 with Loss :200359.8125\n",
      "Epochs 110 with Loss :200326.078125\n",
      "Epochs 120 with Loss :200294.359375\n",
      "Epochs 130 with Loss :200254.734375\n",
      "Epochs 140 with Loss :200216.109375\n",
      "Epochs 150 with Loss :200163.234375\n",
      "Epochs 160 with Loss :200116.984375\n",
      "Epochs 170 with Loss :200060.625\n",
      "Epochs 180 with Loss :200011.421875\n",
      "Epochs 190 with Loss :199953.71875\n",
      "Epochs 200 with Loss :199884.25\n",
      "Epochs 210 with Loss :199819.484375\n",
      "Epochs 220 with Loss :199758.34375\n",
      "Epochs 230 with Loss :199675.171875\n",
      "Epochs 240 with Loss :199609.234375\n",
      "Epochs 250 with Loss :199507.765625\n",
      "Epochs 260 with Loss :199438.875\n",
      "Epochs 270 with Loss :199339.734375\n",
      "Epochs 280 with Loss :199265.421875\n",
      "Epochs 290 with Loss :199152.34375\n",
      "Epochs 300 with Loss :199060.109375\n",
      "Epochs 310 with Loss :198945.90625\n",
      "Epochs 320 with Loss :198879.609375\n",
      "Epochs 330 with Loss :198709.484375\n",
      "Epochs 340 with Loss :198615.640625\n",
      "Epochs 350 with Loss :198478.21875\n",
      "Epochs 360 with Loss :198411.703125\n",
      "Epochs 370 with Loss :198240.03125\n",
      "Epochs 380 with Loss :198178.765625\n",
      "Epochs 390 with Loss :197987.265625\n",
      "Epochs 400 with Loss :197873.078125\n",
      "Epochs 410 with Loss :197700.828125\n",
      "Epochs 420 with Loss :197620.75\n",
      "Epochs 430 with Loss :197466.296875\n",
      "Epochs 440 with Loss :197322.03125\n",
      "Epochs 450 with Loss :197202.84375\n",
      "Epochs 460 with Loss :197011.59375\n",
      "Epochs 470 with Loss :196863.484375\n",
      "Epochs 480 with Loss :196694.015625\n",
      "Epochs 490 with Loss :196517.328125\n",
      "Epochs 500 with Loss :196313.71875\n",
      "Epochs 510 with Loss :196177.59375\n",
      "Epochs 520 with Loss :196032.421875\n",
      "Epochs 530 with Loss :195838.203125\n",
      "Epochs 540 with Loss :195642.03125\n",
      "Epochs 550 with Loss :195510.09375\n",
      "Epochs 560 with Loss :195336.578125\n",
      "Epochs 570 with Loss :195092.34375\n",
      "Epochs 580 with Loss :194884.421875\n",
      "Epochs 590 with Loss :194725.953125\n",
      "Epochs 600 with Loss :194502.78125\n",
      "Epochs 610 with Loss :194337.203125\n",
      "Epochs 620 with Loss :194215.734375\n",
      "Epochs 630 with Loss :193936.640625\n",
      "Epochs 640 with Loss :193668.5\n",
      "Epochs 650 with Loss :193500.765625\n",
      "Epochs 660 with Loss :193292.890625\n",
      "Epochs 670 with Loss :193034.109375\n",
      "Epochs 680 with Loss :192898.671875\n",
      "Epochs 690 with Loss :192712.296875\n",
      "Epochs 700 with Loss :192429.59375\n",
      "Epochs 710 with Loss :192274.859375\n",
      "Epochs 720 with Loss :191964.109375\n",
      "Epochs 730 with Loss :191713.25\n",
      "Epochs 740 with Loss :191504.5625\n",
      "Epochs 750 with Loss :191271.25\n",
      "Epochs 760 with Loss :191030.03125\n",
      "Epochs 770 with Loss :190826.0625\n",
      "Epochs 780 with Loss :190421.21875\n",
      "Epochs 790 with Loss :190388.65625\n",
      "Epochs 800 with Loss :189997.78125\n",
      "Epochs 810 with Loss :189668.21875\n",
      "Epochs 820 with Loss :189574.8125\n",
      "Epochs 830 with Loss :189338.671875\n",
      "Epochs 840 with Loss :188930.125\n",
      "Epochs 850 with Loss :188746.859375\n",
      "Epochs 860 with Loss :188483.671875\n",
      "Epochs 870 with Loss :188066.125\n",
      "Epochs 880 with Loss :187953.265625\n",
      "Epochs 890 with Loss :187641.609375\n",
      "Epochs 900 with Loss :187209.9375\n",
      "Epochs 910 with Loss :187109.59375\n",
      "Epochs 920 with Loss :186834.015625\n",
      "Epochs 930 with Loss :186463.125\n",
      "Epochs 940 with Loss :186207.6875\n",
      "Epochs 950 with Loss :185897.203125\n",
      "Epochs 960 with Loss :185656.9375\n",
      "Epochs 970 with Loss :185304.84375\n",
      "Epochs 980 with Loss :184962.640625\n",
      "Epochs 990 with Loss :184620.921875\n",
      "Epochs 1000 with Loss :184460.765625\n",
      "Epochs 1010 with Loss :183980.8125\n",
      "Epochs 1020 with Loss :183925.140625\n",
      "Epochs 1030 with Loss :183430.15625\n",
      "Epochs 1040 with Loss :183205.0625\n",
      "Epochs 1050 with Loss :182632.328125\n",
      "Epochs 1060 with Loss :182604.953125\n",
      "Epochs 1070 with Loss :182046.640625\n",
      "Epochs 1080 with Loss :181783.828125\n",
      "Epochs 1090 with Loss :181727.703125\n",
      "Epochs 1100 with Loss :181323.984375\n",
      "Epochs 1110 with Loss :180828.484375\n",
      "Epochs 1120 with Loss :180723.265625\n",
      "Epochs 1130 with Loss :180370.84375\n",
      "Epochs 1140 with Loss :179919.203125\n",
      "Epochs 1150 with Loss :179534.203125\n",
      "Epochs 1160 with Loss :179290.0\n",
      "Epochs 1170 with Loss :178875.640625\n",
      "Epochs 1180 with Loss :178304.25\n",
      "Epochs 1190 with Loss :178310.40625\n",
      "Epochs 1200 with Loss :177973.421875\n",
      "Epochs 1210 with Loss :177288.03125\n",
      "Epochs 1220 with Loss :177350.09375\n",
      "Epochs 1230 with Loss :176722.484375\n",
      "Epochs 1240 with Loss :176602.59375\n",
      "Epochs 1250 with Loss :176187.09375\n",
      "Epochs 1260 with Loss :175954.71875\n",
      "Epochs 1270 with Loss :175299.703125\n",
      "Epochs 1280 with Loss :174504.53125\n",
      "Epochs 1290 with Loss :174634.921875\n",
      "Epochs 1300 with Loss :174249.0625\n",
      "Epochs 1310 with Loss :173669.203125\n",
      "Epochs 1320 with Loss :173767.109375\n",
      "Epochs 1330 with Loss :173030.15625\n",
      "Epochs 1340 with Loss :172927.96875\n",
      "Epochs 1350 with Loss :172620.421875\n",
      "Epochs 1360 with Loss :172123.046875\n",
      "Epochs 1370 with Loss :171667.796875\n",
      "Epochs 1380 with Loss :171470.34375\n",
      "Epochs 1390 with Loss :170646.796875\n",
      "Epochs 1400 with Loss :170330.78125\n",
      "Epochs 1410 with Loss :169890.421875\n",
      "Epochs 1420 with Loss :170411.25\n",
      "Epochs 1430 with Loss :169396.0\n",
      "Epochs 1440 with Loss :168457.078125\n",
      "Epochs 1450 with Loss :168522.890625\n",
      "Epochs 1460 with Loss :168049.140625\n",
      "Epochs 1470 with Loss :167460.71875\n",
      "Epochs 1480 with Loss :167447.359375\n",
      "Epochs 1490 with Loss :166901.78125\n",
      "Epochs 1500 with Loss :166462.09375\n",
      "Epochs 1510 with Loss :165629.4375\n",
      "Epochs 1520 with Loss :165210.65625\n",
      "Epochs 1530 with Loss :165173.796875\n",
      "Epochs 1540 with Loss :164813.765625\n",
      "Epochs 1550 with Loss :164154.765625\n",
      "Epochs 1560 with Loss :163736.34375\n",
      "Epochs 1570 with Loss :163294.046875\n",
      "Epochs 1580 with Loss :162960.453125\n",
      "Epochs 1590 with Loss :162671.28125\n",
      "Epochs 1600 with Loss :162063.40625\n",
      "Epochs 1610 with Loss :161973.828125\n",
      "Epochs 1620 with Loss :161311.171875\n",
      "Epochs 1630 with Loss :161412.171875\n",
      "Epochs 1640 with Loss :160352.0625\n",
      "Epochs 1650 with Loss :160174.5625\n",
      "Epochs 1660 with Loss :159774.375\n",
      "Epochs 1670 with Loss :159017.3125\n",
      "Epochs 1680 with Loss :158459.6875\n",
      "Epochs 1690 with Loss :158609.40625\n",
      "Epochs 1700 with Loss :157869.09375\n",
      "Epochs 1710 with Loss :157990.296875\n",
      "Epochs 1720 with Loss :157227.625\n",
      "Epochs 1730 with Loss :156479.828125\n",
      "Epochs 1740 with Loss :156379.828125\n",
      "Epochs 1750 with Loss :155180.265625\n",
      "Epochs 1760 with Loss :155405.84375\n",
      "Epochs 1770 with Loss :155186.734375\n",
      "Epochs 1780 with Loss :154414.859375\n",
      "Epochs 1790 with Loss :154372.234375\n",
      "Epochs 1800 with Loss :153267.828125\n",
      "Epochs 1810 with Loss :152737.3125\n",
      "Epochs 1820 with Loss :152625.09375\n",
      "Epochs 1830 with Loss :152295.734375\n",
      "Epochs 1840 with Loss :151258.640625\n",
      "Epochs 1850 with Loss :150843.28125\n",
      "Epochs 1860 with Loss :150761.828125\n",
      "Epochs 1870 with Loss :150280.3125\n",
      "Epochs 1880 with Loss :149940.0\n",
      "Epochs 1890 with Loss :149378.625\n",
      "Epochs 1900 with Loss :148892.53125\n",
      "Epochs 1910 with Loss :148856.25\n",
      "Epochs 1920 with Loss :147201.625\n",
      "Epochs 1930 with Loss :147921.5\n",
      "Epochs 1940 with Loss :146605.609375\n",
      "Epochs 1950 with Loss :146800.140625\n",
      "Epochs 1960 with Loss :146055.296875\n",
      "Epochs 1970 with Loss :146238.921875\n",
      "Epochs 1980 with Loss :144874.359375\n",
      "Epochs 1990 with Loss :144432.59375\n",
      "Epochs 2000 with Loss :144693.21875\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "\n",
    "final_loss = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i = i+1\n",
    "    y_pred = model(train_cat,train_cont)\n",
    "    loss = torch.sqrt(loss_function(y_pred,y_train)) #RMSE\n",
    "    \n",
    "    final_loss.append(loss)\n",
    "    if i%10 == 0 :\n",
    "        print(\"Epochs {} with Loss :{}\".format(i,loss))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RMSE Loss')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd5xU5dn/8c+1uyy9sypSXEDAGhBWFBV7QcgTjDEGf0aJkphETSyJCrbYRaPxibHFRCP6JNgLCYgFsURBWBBEmqyAAtK70nev3x9zM84sWygzc7Z836/XvPac65S55my59pz7Pvcxd0dERCSVsqJOQEREah4VFxERSTkVFxERSTkVFxERSTkVFxERSbmcqBOoKlq1auX5+flRpyEiUq1Mnjx5pbvnlY6ruAT5+fkUFhZGnYaISLViZl+WFddlMRERSTkVFxERSTkVFxERSTkVFxERSTkVFxERSTkVFxERSTkVFxERSbm03ediZu2Ap4F9AQced/c/m1kL4DkgH1gAnOvua8zMgD8D/YCNwM/cfUrY1yDgxrDrO9x9eIj3BJ4C6gOjgSvc3ct7j3R8zrGzljFt0TrqZBl1crLIyTLqZGdRJzuLnGyjTnZsPicri3p1smhUN4cGuTk0rJtN43p1aFa/DllZlo7UREQik86bKLcDv3P3KWbWGJhsZm8BPwPGuvswMxsCDAGuA84EOofXUcCjwFGhUPwBKCBWpCab2chQLB4FfgF8TKy49AVeD/ss6z1S7r3PV/D0+DLvIdolWQbNGuTSomF4NcilRaNcWjbMZZ8m9WjdpB77N6tP2xb1aVKvTgozFxFJH8vUw8LM7DXgofA60d2XmFlr4F1372pmfw3TI8L6c4ATd7zc/Zch/lfg3fAa5+4Hhfh5O9bbsW3p96gov4KCAt/TO/Tdne0lzvZiZ1tJCdu2l7C9xNlWXBKLFZewrdjZtK2YjVu38+2W7XyzpZj1m7axZuNWVn27ldXfbGX1xq2s/jb2WrNxK6W/NY3r5dCmWX3at2hAh7yGdGrViA55DenYqiEtG9Xdo9xFRPaGmU1294LS8YwM/2Jm+cARxM4w9nX3JWHRUmKXzQDaAAsTNlsUYhXFF5URp4L3KJ3XJcAlAO3bt9/NT5W0n3D5C+qTvcf7SVRc4qz6ZgtL1m1m8dpNLFqzkUVrNrFozSa+WPEN4+YsZ1vxd9WnRcNcDtqvMYe0bsJBrZtwcOvGHLhPI+rmpCYfEZHdkfbiYmaNgJeAK919faxpJSa0j6T11Kmi93D3x4HHIXbmks48dld2lrFPk3rs06Qe3do122n59uISvl67mXkrv6Fo+TfMXfYNs5eu55kJX7JlewkAOVlGp7xGHNy6MQe1bkKnvEYc3bEFjXV5TUTSLK3FxczqECss/3T3l0N4mZm1TrhktTzEFwPtEjZvG2KLiV0aS4y/G+Jty1i/oveoMXKys2jfsgHtWzbgxK77xOPFJc78ld8ya8l6Zi1Zz+ylG/h4/mpenfo1ECtaXfdtzPfaNqVbu2b0PXQ/mjfMjepjiEgNlbY2l9D7aziw2t2vTIj/EViV0Njewt2vNbP+wOXEeosdBTzo7r1Cg/5koEfYxRSgp7uvNrOJwG/5rkH/L+4+urz3qCjfvWlzqQ5WfrOFj+etZuaSdbz/+UqmL14XX9YxryHd2zbj+91ac1SHljSsq8GyRWTXlNfmks7ichzwATAdKAnh64kVgueB9sCXxLoJrw7F6CFiPb42Ahe5e2HY18VhW4A73f0fIV7Ad12RXwd+Ey6DtSzrPSrKt6YXl9KKS5wP5q5gxtfrmbpwLRPnr2bdpm1kGRy6f1OOObAlxx3YiiPzW1CvjtptRKRsGS8u1U1tKy6lbdy6nQnzVjF14TomfLGKTxauYVuxk5udRc8DmtO7U0tO7JrH4W2akthuJiK1m4pLJWp7cSnt2y3bmbhgNR8VreS/RauYtWR9fNnhbZoyoPv+XNg7n9wcDfIgUpupuFRCxaViC1dvZPT0Jdz9+uykeLd2zfhem6bc+P2D1e1ZpBZScamEisuuW7Z+My8ULuS+Nz+Px3LD0DdDzzyIH3RvQ9P66u4sUhuouFRCxWXPLFqzkY++WMVj737BvJXfxuOtGuVyx1mH0b1dc/ZrWi/CDEUknVRcKqHisvdWbNjCg2PnMn3xOqYuXJu07LYBh3LB0QeoM4BIDaPiUgkVl9RavmEzd46axb+nfU1Jwo9Yn86t+HmfjpzQJS+65EQkZVRcKqHikj5Fyzdwwyuf8fH85FuNhl/ci94dW6rHmUg1puJSCRWXzBg3ZzkX/WPSTvFnBveiT2edzYhUNyoulVBxyaxNW4t5e9Yy7ho9iyXrNsfjfTq34sGBR2i8M5FqQsWlEiou0Zn85Woee28eb81cFo+1aVafpy46ks77No4wMxGpjIpLJVRcordh8zaue+lTRk9fmhR/9PwenHl464iyEpGKqLhUQsWl6igpcf758Zfc9NqMpHjPA5rz1EVH6nk0IlWIikslVFyqpnGzl3PvG3OSxjY7uHUTXrn0GI3WLFIFqLhUQsWlatu0tZgfPvIhs5duSIo//8ve9OrQIqKsRKS84qIbDKRaqJ+bzZgrj+f9a05i8HEd4vFz/zqeC574mLUbt0aYnYiUpjOXQGcu1cvmbcWc/sD7fLV6YzyWm53F+9eepLHMRDJIl8UqoeJSfd07ZjaPvPtFfL7nAc259oyuHNWxZYRZidQOKi6VUHGp/sZ8tpTfjviErcWxp2rXzcni/35+FEfmq01GJF1UXCqh4lIzuDtTvlrL/W/O4aMvVsXj1/c7iF/06ahRmUVSTA36UiuYGT0PaM6/fnE0w84+PB6/a/RsOgwdzYdFKyPMTqT2UHGRGmtgr/YsGNaf83q1i8fO//vH5A8ZRdHyDRVsKSJ7S5fFAl0Wq9m2FZfwl7FzefyDeWzeFmuTadkwl4k3nEp2li6ViewptblUQsWl9nh5yiKufn5afL5jXkMePb8nXffTIJkiu0vFpRIqLrVLcYnztw/mMez12UnxPw/szoDubSLKSqT6UYO+SILsLONXJ3Ri9u19GdT7gHj8imenct8bcyLMTKRm0JlLoDOX2u3bLdu59qVPGfXpknjsjEP35dHze5KlNhmRcmX8zMXMnjSz5Wb2WUKsm5mNN7PpZvZvM2uSsGyomRWZ2RwzOyMh3jfEisxsSEK8g5l9HOLPmVluiNcN80VheX66PqPUHA3r5vDQeUdw6w8OjcfemLGMjteP5s0ZSyvYUkTKks7LYk8BfUvF/g4McffDgVeAawDM7BBgIHBo2OYRM8s2s2zgYeBM4BDgvLAuwD3AA+5+ILAGGBzig4E1If5AWE+kUmbGoGPymfaH07nnR9/dI3PJM5PJHzKKG1+dHmF2ItVL2oqLu78PrC4V7gK8H6bfAn4UpgcAz7r7FnefDxQBvcKryN3nuftW4FlggMVusz4ZeDFsPxw4K2Ffw8P0i8ApptuyZTc0rV+HnxzZnvl390tqj/m/CV/xr4+/YsK8VZSU6HKySEUy3aA/g9gff4AfAzvubmsDLExYb1GIlRdvCax19+2l4kn7CsvXhfV3YmaXmFmhmRWuWLFiLz6W1ERmxq0DDmPqzafFY9e/Mp2Bj0/gyuemRpiZSNWX6eJyMXCpmU0GGgORPoTD3R939wJ3L8jLy4syFanCmjXIZd5d/ejRvlk8NnLa1+QPGcXChCH/ReQ7OZl8M3efDZwOYGZdgP5h0WK+O4sBaBtilBNfBTQzs5xwdpK4/o59LTKzHKBpWF9kj2VlGS9feiwAY2ctY/DwWM/CPveOo3XTejz60550b9esol2I1CoZPXMxs33C1yzgRuCxsGgkMDD09OoAdAYmApOAzqFnWC6xRv+RHus/PQ44J2w/CHgtYV+DwvQ5wDuu/taSQqccvC//vvy4+PySdZs56+EPmbSgdBOjSO2Vzq7II4DxQFczW2Rmg4n19vocmA18DfwDwN1nAM8DM4ExwGXuXhzOSi4H3gBmAc+HdQGuA642syJibSpPhPgTQMsQvxqId18WSZXD2zZl3l39ePOq42nRMBeAHz82np8PL2TL9uKIsxOJnm6iDHQTpeyNh96Zy31vfh6fP6xNE/7zmz4RZiSSGRr+RSSNLj+5MzNujd/7y2eL15M/ZBTvzlkeYVYi0VFxEUmRhnVzmHnbGTx10ZHx2M/+MYkj73ybDZu3RZiZSOapuIikUIPcHE7sug//SCgwKzZs4fBb3uRXz0xGl6GltlBxEUmDk7ruw4Jh/bl9wHdjlY2ZsZRb/z2TQvUqk1pAxUUkjS7onc+0m0+nW9umADz10QLOeWw8T49fwOpvI72HWCStVFxE0qxpgzq8dvlx/E+3/eOxm1+bQY/b32LzNnVblppJxUUkQ/78k+7MvfNMhp55UDx2xG1vMXfZhgizEkkPFReRDMnKMupkZ/HLEzrx4HlHALBpWzGnPfA+J933rhr7pUZRcRGJwA+67c+Um74bbXn+ym/pMHQ03W59k2IN5y81gIqLSERaNMxlwbD+/Oc3341Ttm7TNjpdP1pDyEi1p+IiErHD2jTlvWtOTIp1vXEM73+uZwxJ9aWxxQKNLSZVwYyv19H/wf8mxW4fcCgX9M6PJiGRSmhsMZFq4ND9m7JgWH9uS7j58qbXZjDj63URZiWy+1RcRKqgC3vn8+eB3ePz/R/8L1c8+0mEGYnsHhUXkSpqQPc2zL+7X3z+tamxRyu/ULiQjVu3R5iZSOVUXESqMDPjk5tO48LeB8Rj17z4KYfc/EaEWYlUTsVFpIpr3jCX2wYcxud3nMnxXfLi8fwho/hq1cYIMxMpn4qLSDWRm5PFP352JHmN68Zjx/9xHEvXbdbd/VLlqLiIVCPZWcakG07llUuPiceOvnssv/6/KRFmJbIzFReRauiI9s2Z9ofT4/NjZiwlf8goZi9dH2FWIt9RcRGppprWr8Ont5zOtX27xmN9//cDhrz0KSUan0wipuIiUo01qVeHS088MGl8smcnLaTXXW9rfDKJlIqLSA1wWJumTL35NA5u3QSAld9speuNY7j5tc94cfKiiLOT2kjFRaSGaNYgl9G/PY7TDtk3Hnt6/Jf8/oVpbC8uiTAzqY1UXERqEDPjbxcW0P/w1knxA294XY9UloxKW3ExsyfNbLmZfZYQ625mE8xsqpkVmlmvEDcze9DMiszsUzPrkbDNIDObG16DEuI9zWx62OZBM7MQb2Fmb4X13zKz5un6jCJV1cPn9+CqU7swoPv+8dhBN41h+YbNEWYltUk6z1yeAvqWit0L3Oru3YGbwzzAmUDn8LoEeBRihQL4A3AU0Av4Q0KxeBT4RcJ2O95rCDDW3TsDY8O8SK1zxamd+fPAI2jZMDce63XnWPKHjKJwwWomzl8dYXZS06WtuLj7+0Dpn14HmoTppsDXYXoA8LTHTACamVlr4AzgLXdf7e5rgLeAvmFZE3ef4LFbk58GzkrY1/AwPTwhLlIrFd54KtNuPp0j2jeLx855bDzn/nV8hFlJTZfpNpcrgT+a2ULgPmBoiLcBFiastyjEKoovKiMOsK+7LwnTS4F9EanFzIymDerwwi9786MebZOWTflqTURZSU2X6eLya+Aqd28HXAU8kc43C2c15d5NZmaXhLafwhUr9EhZqdlysrO4/9xuTLz+lHjs7Ec+4urnp0aYldRUmS4ug4CXw/QLxNpRABYD7RLWaxtiFcXblhEHWBYumxG+Li8vGXd/3N0L3L0gLy+vvNVEapR9mtRjzJV94vMvT1nMiIlfRZiR1ESVFhczO9bMGobpn5rZn8zsgMq2K8fXwAlh+mRgbpgeCVwYeo0dDawLl7beAE43s+ahIf904I2wbL2ZHR16iV0IvJawrx29ygYlxEUkOGi/Jrx22bHx+aEvTyd/yChWfbMlwqykJtmVM5dHgY1m1g34HfAFsQb0CpnZCGA80NXMFpnZYGK9u+43s2nAXcR6hgGMBuYBRcDfgEsB3H01cDswKbxuCzHCOn8P23wBvB7iw4DTzGwucGqYF5FSurVrxmM/7UHjejnxWM873ubRd7/QEP6y16yyHyIzm+LuPczsZmCxuz+xI5aZFDOjoKDACwsLo05DJBLTFq5lwMMfxucvPbETnfIacXaPNoRbyETKZGaT3b2gdHxXzlw2mNlQ4KfAKDPLAuqkOkERiU63ds2484eHxecfefcLfvfCNMbOKrfJUqRCu1JcfgJsAQa7+1Jijed/TGtWIpJx5x91AO/+/sSk2M+fLmTdpm3RJCTV2i6duQB/dvcPzKwL0B0Ykd60RCQK+a0a8sSg5Csc3W59k/who1i3UUVGdt2uFJf3gbpm1gZ4E7iA2NAuIlIDnXLwvsy+vS+XHN8xKd7/Lx8wb8U3EWUl1c2uFBdz943A2cAj7v5j4LBKthGRaqxenWyu73cwT1/cKx5btGYTJ9//HsvXa/BLqdwuFRcz6w2cD4zaje1EpJo7vkseC4b1T4r1umssi9ZsjCgjqS52pUhcSWwMsFfcfYaZdQTGpTctEalKEs9gAI67ZxzPTPiSNd9ujSgjqeoqvc8lvqJZIwB3r5EXXXWfi0jFtheXMG3RWn70aPJoyvPv7qd7YWqxPb7PxcwON7NPgBnATDObbGaHpiNJEam6crKz6NG+OWf3aJMU7zB0tO7ol53symWxvwJXu/sB7t6e2BAwf0tvWiJSFZkZfzq3+07xv30wj63bSyLISKqqXSkuDd093sbi7u8CDdOWkYhUeSN+cTT3/uh78fm7Rs+my42v84W6KkuwK8VlnpndZGb54XUjsUEmRaSW6t2pJece2S7p2TAAp9z/Hifd964uk8kuFZeLgTxiz2F5CWgFXJTOpESketinST0WDOvP3WcfHo/NX/kt789dGWFWUhVUWlzcfY27/9bde7h7T3e/ErgxA7mJSDVxXq/2SfODnpzIknWbIspGqoI9vRny3JRmISLV3gu/6s2rCQ8g6333O+QPGcXGrdsjzEqisqfFRZ3aRSTJkfkt6N6uWVJDP8DZj3zEH9+YHVFWEpWc8haYWYvyFqHiIiLlOPfIdvyoZ1s6XT8agNlLNzB76QYa5OZw2UkHRpydZEq5xQWYDDhlFxKN+SAi5crOMubeeSadb3g9HvvjG3NomJvNhb3zycrS/6c1XbmXxdy9g7t3DF9LvzqWt52ICECd7CzGlXr42C3/nskNr06PJiHJKI1uLCJp06FVQxYM6881Z3SNx0ZMXMiPH/uIbcW6o78mU3ERkbS77KQDk3qSTVqwhs43vM6KDVsizErSScVFRDKie7tmO8WOvPNtlunhYzVSucXFzE5OmO5QatnZ6UxKRGqmsb87gV8e35Hzj/rupsuj7hrL4rW64bKmqejM5b6E6ZdKLdMd+iKy2zrlNWJov4O584eHJ8WPHfYO1734aURZSTpUVFysnOmy5kVEdsvE60/he22bxuefK1yoQS9rkIqKi5czXda8iMhu2adJPUZefhxvX31CPDZ/5bd0GDpaDf01QEXFpaOZjTSzfydM75jvUMF2AJjZk2a23Mw+S4g9Z2ZTw2uBmU1NWDbUzIrMbI6ZnZEQ7xtiRWY2JCHewcw+DvHnzCw3xOuG+aKwPH+3joiIZNSB+zSi8MZTk2IvTVkUUTaSKhXdoT8gYfq+UstKz5flKeAh4OkdAXf/yY5pM7sfWBemDwEGAocC+wNvm1mXsOrDwGnAImCSmY1095nAPcAD7v6smT0GDAYeDV/XuPuBZjYwrBd/XxGpelo1qsspB+3D2NnLARj2+mx6HtCcbdtLePfzFVzf7+CIM5TdZbt6fdPM6gCHAYvdffkubpMP/MfdDysVN+Ar4GR3n2tmQwHc/e6w/A3glrD6Le5+RogPDbFhwApgP3ffbma9d6y3Y1t3H29mOcBSIM8r+aAFBQVeWFi4Kx9LRNJg09ZiJsxfxcipX/PKJ4uTls27q5+GjKmizGyyuxeUjlfUFfkxMzs0TDcFphE7C/nEzM7by3z6AMvcfW6YbwMsTFi+KMTKi7cE1rr79lLxpH2F5evC+jsxs0vMrNDMClesWLGXH0lE9kb93GxO6roPfzq3207Lpi9eF0FGsjcqanPp4+4zwvRFwOfufjjQE7h2L9/3PGDEXu5jr7n74+5e4O4FeXl5UacjIoCZ8eGQk5NiAx7+UPfCVDMVFZfEkY9PA14FcPele/OG4VLV2cBzCeHFQLuE+bYhVl58FdAs7CsxnrSvsLxpWF9Eqok2zeqzYFh/hp55UDx27LB3uOnVzyrYSqqSiorLWjP7vpkdARwLjIH4H+z6e/GepwKz3T2xO8hIYGDo6dUB6AxMBCYBnUPPsFxijf4jQ/vJOOCcsP0g4LWEfQ0K0+cA71TW3iIiVVPfw/ZLmn9mwpfc98aciLKR3VFRcfklcDnwD+DKhDOWU4BRle3YzEYA44GuZrbIzAaHRQMpdUksXH57HphJrIhd5u7Foc3kcuANYBbwfMKluuuAq82siFibyhMh/gTQMsSvBoYgItVS+xYNuPUHhybFHhpXRNHybyLKSHbVLvcWq+nUW0yk6npx8iJ+/8K0pNjnd5xJbo7G3o1aeb3FKnrM8YMV7dDdf5uKxEREKvOjHm04on0zpny5hmvCGGRdbnyd7u2a8fwve6vIVEEV3UT5K+AzYpervkbjiYlIRMyMTnmN6JTXiCb16/DLZyYDMHXhWrrc+DoLhvWPOEMpraJy3xp4HDgDuACoA7zm7sPdfXgmkhMRKe2MQ/fjvh8n3wtzsga8rHLKLS7uvsrdH3P3k4jd59IMmGlmF2QsOxGRMpzTsy2vXHpMfH7eym+5/T+zIsxISqv0QqWZ9QCuAH4KvA5MTndSIiKVOaJ9c/71i6Pi809+OJ/b/zOTTVuLWfmNRlWOWrm9xczsNqA/sS7AzwJjEoZbqXHUW0ykeioucTpdP3qnuNphMmO3xxYj9rTJZkA34G5gipl9ambTzUyPjBORKiE7y5h755k7xV+arGH7o1RRb7FKn9kiIlIV1MnO4opTOvPnsXPjsd+9MI1jD2zFfk3rRZhZ7VVRg/6XZb2IjTh8XOZSFBGp3FWndWHWbX2TYkffPVZ380ekoiH3m4SnQz5kZqdbzG+AecC5mUtRRGTX1M/N5q2rjk+Knfqn98gfMoqNW2tsk3GVVFGbyzNAV2A68HO+GyjyLHcfUMF2IiKR6bxvY15O6Ka8wxMfzI8gm9qrouLS0d1/5u5/Jfb8lUOAM9x9agXbiIhErkf75kn3wQDc/9bnutEygyoqLtt2TLh7MbDI3TenPyURkb13RPvmzL69L53yGsZjHYaO5ty/jmfL9uIIM6sdKiou3cxsfXhtAL63Y9rM1mcqQRGRPVWvTjZvX31CUmzi/NV0vXEMi9ZsjCir2qGi3mLZ7t4kvBq7e07CdJNMJikisqfMjHl39dsp/vPhumk6nTROtYjUeFlZxqQbTk2KzV66gaueUxNyuqi4iEitkNe4LpNvTC4wr3yyOKJsaj4VFxGpNVo2qsuCYf15ZnCveOycRz/i3jGzeW7SVxFmVvOouIhIrdOncx5/vzA21mLhl2t45N0vuO6l6RFnVbOouIhIrXTqIftSWOoy2cPjinQvTIqouIhIrdWqUV2u63tQfP6Pb8zh5tdmRJhRzaHiIiK12tk92tCmWf34/DMTvuRPb86hpERnMHtDxUVEarV9m9TjwyEnM+TM785gHnyniL+8U0SxCsweU3EREQF+dUInLjo2Pz7/wNufM/Dx8bw+fUl0SVVjKi4iIsFVp3VJmp+0YA2//ucU3p65LKKMqi8VFxGRoEm9OiwY1n+n+M+f1lAxuyttxcXMnjSz5Wb2Wan4b8xstpnNMLN7E+JDzazIzOaY2RkJ8b4hVmRmQxLiHczs4xB/zsxyQ7xumC8Ky/PT9RlFpGa6+fuH7BQbO0tnL7sjnWcuTwFJzxw1s5OAAUA3dz8UuC/EDwEGAoeGbR4xs2wzywYeBs4k9jyZ88K6APcAD7j7gcAaYHCIDwbWhPgDYT0RkV128XEdGHNln6TY4OGFPDfpK4a+/KmearkL0lZc3P19YHWp8K+BYe6+JayzPMQHAM+6+xZ3nw8UAb3Cq8jd57n7VuBZYICZGXAy8GLYfjhwVsK+hofpF4FTwvoiIrvsoP2a8N/rTuLSEzvFY9e9NJ0RExdyyM1vkD9kFGu+3RphhlVbpttcugB9wuWq98zsyBBvAyxMWG9RiJUXbwmsdfftpeJJ+wrL14X1d2Jml5hZoZkVrlixYq8/nIjULG2bN+Davgfx5M8Kylz+h5G64bI8mS4uOUAL4GjgGuD5KM8q3P1xdy9w94K8vLyo0hCRKu7kg/ZlwbD+dEx4qiXAmo06cylPpovLIuBlj5kIlACtgMVAu4T12oZYefFVQDMzyykVJ3GbsLxpWF9EZK+887sTk+Y/mLuSR9/9IppkqrhMF5dXgZMAzKwLkAusBEYCA0NPrw5AZ2AiMAnoHHqG5RJr9B/psZHlxgHnhP0OAl4L0yPDPGH5O66R6EQkRV6+9Jik+XvGzI4PFbNu0za2FZdEkVaVk86uyCOA8UBXM1tkZoOBJ4GOoXvys8CgcBYzA3gemAmMAS5z9+LQZnI58AYwC3g+rAtwHXC1mRURa1N5IsSfAFqG+NVAvPuyiMje6tG+OR8NOTkp1vH60ZSUON1ufZNrXpgWUWZVi+mf+piCggIvLNSNUiKya16esoirn/+ukPzlvCP4zYhPAMq8EbOmMrPJ7r5TjwfdoS8isgfO7tGWx37aMz6/o7AAbNpaHEVKVYqKi4jIHup72H5lxg++eUyGM6l6VFxERPbCtJtPLzM+upaPpqziIiKyF5o2qMM/f34U5x/Vnj6dW8Xjl/5zSoRZRU/FRURkLx17YCvu/OHhPDP4KBrXzYnHz37kQ7Zsr53tLyouIiIpNOKSo+PTU75aS9cba2f7i4qLiEgKHdamKROvPyUplj9kFH//YF5EGUVDxUVEJMXyGtfdKXbHqFm8NnVxGWvXTCouIiIpZmZlPnDsimenRpBNNLEQ83YAAA1YSURBVFRcRETS4OLjOvCLPh346dHtk+J9//f9WjH+mIqLiEia3ND/EO446/Ck2OylG+h8w+ss37A5oqwyQ8VFRCTNCm88dafYFSOmUlxSc8d2VHEREUmzVo3q8t41JybFxs9bxV/fr7nPglFxERHJgANaNuSzW89Iit07Zg7H3D2WWUvWR5RV+qi4iIhkSKO6Ocy+vS+XntgpHvt63Wauem4qX6/dFGFmqafiIiKSQfXqZHPNGV05+aB94rHZSzdwzLB3Iswq9VRcREQyzMx45PweO8XHf7GKzdtqxlhkKi4iIhGoVyebmbclt8Gc97cJHHTTGOav/Jbq/pRgFRcRkYg0yM3hrO777xQ/6b53+ceHCzKfUAqpuIiIROjOHx7O1ad12Sl+239mUlKN74NRcRERiVDDujmc0CWvzGUPvjM3w9mkjoqLiEjEurVrxtSbT2PmbWfwox5t4/H/fXtutb2LX8VFRKQKaNYglwa5Odx/bjcm3vDd82A6XT+ay6rhI5NVXEREqph9GtdLmh81fUm166Ks4iIiUgXNv7tf0vxBN43h82UbIspm96m4iIhUQWbGc5ccnRT77YhPeOWTRUxasDqirHZd2oqLmT1pZsvN7LOE2C1mttjMpoZXv4RlQ82syMzmmNkZCfG+IVZkZkMS4h3M7OMQf87MckO8bpgvCsvz0/UZRUTS6aiOLbkp4YmWs5du4KrnpvHjx8ZHmNWuSeeZy1NA3zLiD7h79/AaDWBmhwADgUPDNo+YWbaZZQMPA2cChwDnhXUB7gn7OhBYAwwO8cHAmhB/IKwnIlItXXxsfpnxqn4Hf9qKi7u/D+zqudsA4Fl33+Lu84EioFd4Fbn7PHffCjwLDDAzA04GXgzbDwfOStjX8DD9InBKWF9EpNoxM6bfcvpO8Q5DRwMwcf5qFq7emOm0KhVFm8vlZvZpuGzWPMTaAAsT1lkUYuXFWwJr3X17qXjSvsLydWH9nZjZJWZWaGaFK1as2PtPJiKSBo3r1eGDa0+iV36LpPjfP5jHuX8dT597x/HVqqpVYDJdXB4FOgHdgSXA/Rl+/yTu/ri7F7h7QV5e2XfIiohUBe1aNOD5X/Vm3O9PjMfuGDUrPn3zyM/K2Co6GS0u7r7M3YvdvQT4G7HLXgCLgXYJq7YNsfLiq4BmZpZTKp60r7C8aVhfRKTay2/ZgJysna/0r/pmawTZlC+jxcXMWifM/hDYUWpHAgNDT68OQGdgIjAJ6Bx6huUSa/Qf6bGWrHHAOWH7QcBrCfsaFKbPAd7xqt7yJSKyi8yMorv67RSfvngd+UNGsXV7SQRZ7SydXZFHAOOBrma2yMwGA/ea2XQz+xQ4CbgKwN1nAM8DM4ExwGXhDGc7cDnwBjALeD6sC3AdcLWZFRFrU3kixJ8AWob41UC8+7KISE3xk4J2ZcbXbdqW4UzKZvqnPqagoMALCwujTkNEZJd8vXYTvxnxCQ/9vyPoffd3j0j+07ndODth8Mt0M7PJ7l5QOp5T1soiIlK17d+sPi/9+pid7ne5+vlpFC3/hvN6taddiwYRZafhX0REqjUzo0FudlLskXe/oM+94yLKKEbFRUSkmvv0D6fz0q977xR/8r/zWbZ+cwQZqbiIiFR7OdlZ9DygBe1LXQa77T8zIzuDUXEREakhXr3s2J1iW7eX8NnidRnPRcVFRKSGaNEwlwXD+nPfj7slxb//l//y1IfzM5qLiouISA1zTs+29Dt8v6TYLf+eyR3/mcmEeZkZsETFRUSkBnrk/J58NOTkpNjf/zufgY9P4E9vzkn7+6u4iIjUUPs3q8/nd5y5U/zBd4rS/t4qLiIiNVhuThZXndplp3i6R2dRcRERqeGuOLXzTjdavjVzWVrfU8VFRKQW+Ncvjk6av+SZyQx46L98MHcFGzanfrBLFRcRkVqge7tmPHdJcoGZtmgdFzwxkcIFa1L+fiouIiK1xFEdW7JgWP+d4i0b5ab8vVRcRERquQ6tGqZ8nyouIiK1zO0DDqV5gzrx+cb16lSw9p7R81xERGqZC3rnc0HvfN7/fAWrv92alvdQcRERqaWO75KXtn3rspiIiKSciouIiKSciouIiKSciouIiKSciouIiKSciouIiKSciouIiKSciouIiKScpfuBMdWFma0AvtzDzVsBK1OYTqoor92jvHZPVc0Lqm5uNTGvA9x9p7sxVVxSwMwK3b0g6jxKU167R3ntnqqaF1Td3GpTXrosJiIiKafiIiIiKafikhqPR51AOZTX7lFeu6eq5gVVN7dak5faXEREJOV05iIiIimn4iIiIimn4rKXzKyvmc0xsyIzG5LB921nZuPMbKaZzTCzK0L8FjNbbGZTw6tfwjZDQ55zzOyMNOe3wMymhxwKQ6yFmb1lZnPD1+Yhbmb2YMjtUzPrkaacuiYcl6lmtt7MrozimJnZk2a23Mw+S4jt9vExs0Fh/blmNihNef3RzGaH937FzJqFeL6ZbUo4bo8lbNMzfP+LQu6Whrx2+/uW6t/XcvJ6LiGnBWY2NcQzebzK+/uQuZ8xd9drD19ANvAF0BHIBaYBh2TovVsDPcJ0Y+Bz4BDgFuD3Zax/SMivLtAh5J2dxvwWAK1Kxe4FhoTpIcA9Ybof8DpgwNHAxxn63i0FDojimAHHAz2Az/b0+AAtgHnha/Mw3TwNeZ0O5ITpexLyyk9cr9R+JoZcLeR+Zhry2q3vWzp+X8vKq9Ty+4GbIzhe5f19yNjPmM5c9k4voMjd57n7VuBZYEAm3tjdl7j7lDC9AZgFtKlgkwHAs+6+xd3nA0XE8s+kAcDwMD0cOCsh/rTHTACamVnrNOdyCvCFu1c0KkPajpm7vw+sLuP9duf4nAG85e6r3X0N8BbQN9V5ufub7r49zE4A2la0j5BbE3ef4LG/UE8nfJaU5VWB8r5vKf99rSivcPZxLjCion2k6XiV9/chYz9jKi57pw2wMGF+ERX/gU8LM8sHjgA+DqHLw6ntkztOe8l8rg68aWaTzeySENvX3ZeE6aXAvhHlBjCQ5F/6qnDMdvf4RHHcLib2H+4OHczsEzN7z8z6hFibkEsm8tqd71umj1cfYJm7z02IZfx4lfr7kLGfMRWXas7MGgEvAVe6+3rgUaAT0B1YQuy0PArHuXsP4EzgMjM7PnFh+A8tkn7wZpYL/AB4IYSqyjGLi/L4lMfMbgC2A/8MoSVAe3c/Arga+JeZNclgSlXu+1bKeST/A5Px41XG34e4dP+MqbjsncVAu4T5tiGWEWZWh9gPzj/d/WUAd1/m7sXuXgL8je8u42Q0V3dfHL4uB14JeSzbcbkrfF0eRW7ECt4Ud18WcqwSx4zdPz4Zy8/MfgZ8Hzg//FEiXHZaFaYnE2vP6BJySLx0lpa89uD7lsnjlQOcDTyXkG9Gj1dZfx/I4M+YisvemQR0NrMO4b/hgcDITLxxuJ77BDDL3f+UEE9sq/ghsKMXy0hgoJnVNbMOQGdijYjpyK2hmTXeMU2sQfizkMOO3iaDgNcScrsw9Fg5GliXcOqeDkn/UVaFY5bwfrtzfN4ATjez5uGS0OkhllJm1he4FviBu29MiOeZWXaY7kjs+MwLua03s6PDz+mFCZ8llXnt7vctk7+vpwKz3T1+uSuTx6u8vw9k8mdsb3ok6BXvZfE5sf9Cbsjg+x5H7JT2U2BqePUDngGmh/hIoHXCNjeEPOewl71RKsmtI7GeONOAGTuOC9ASGAvMBd4GWoS4AQ+H3KYDBWnMrSGwCmiaEMv4MSNW3JYA24hdxx68J8eHWBtIUXhdlKa8iohdd9/xc/ZYWPdH4fs7FZgC/E/CfgqI/bH/AniIMBpIivPa7e9bqn9fy8orxJ8CflVq3Uwer/L+PmTsZ0zDv4iISMrpspiIiKSciouIiKSciouIiKSciouIiKSciouIiKSciotImplZsSWPxpyy0bMtNtLuZ5WvKZJZOVEnIFILbHL37lEnIZJJOnMRiYjFnvVxr8We4zHRzA4M8XwzeycMyDjWzNqH+L4We57KtPA6Juwq28z+ZrHndrxpZvXD+r+12PM8PjWzZyP6mFJLqbiIpF/9UpfFfpKwbJ27H07sruz/DbG/AMPd/XvEBol8MMQfBN5z927EniEyI8Q7Aw+7+6HAWmJ3gkPseR1HhP38Kl0fTqQsukNfJM3M7Bt3b1RGfAFwsrvPC4MMLnX3lma2kthQJttCfIm7tzKzFUBbd9+SsI98Ys/b6BzmrwPquPsdZjYG+AZ4FXjV3b9J80cVidOZi0i0vJzp3bElYbqY79pS+xMbL6oHMCmM1CuSESouItH6ScLX8WH6I2Ij9gKcD3wQpscCvwYws2wza1reTs0sC2jn7uOA64CmwE5nTyLpov9kRNKvvplNTZgf4+47uiM3N7NPiZ19nBdivwH+YWbXACuAi0L8CuBxMxtM7Azl18RG5C1LNvB/oQAZ8KC7r03ZJxKphNpcRCIS2lwK3H1l1LmIpJoui4mISMrpzEVERFJOZy4iIpJyKi4iIpJyKi4iIpJyKi4iIpJyKi4iIpJy/x9x9X0/Hu7cDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs),final_loss)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"RMSE Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE loss:140493.28125\n"
     ]
    }
   ],
   "source": [
    "#on test set\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(test_cat,test_cont)\n",
    "    loss = torch.sqrt(loss_function(y_pred,y_test))\n",
    "print(\"RMSE loss:{}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>30021.998047</td>\n",
       "      <td>99978.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>138887.0</td>\n",
       "      <td>46535.929688</td>\n",
       "      <td>92351.070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>175500.0</td>\n",
       "      <td>30670.205078</td>\n",
       "      <td>144829.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>109510.937500</td>\n",
       "      <td>85489.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>142500.0</td>\n",
       "      <td>45733.476562</td>\n",
       "      <td>96766.523438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>265900.0</td>\n",
       "      <td>58049.957031</td>\n",
       "      <td>207850.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>224900.0</td>\n",
       "      <td>71618.976562</td>\n",
       "      <td>153281.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>248328.0</td>\n",
       "      <td>84027.523438</td>\n",
       "      <td>164300.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>33169.804688</td>\n",
       "      <td>136830.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>465000.0</td>\n",
       "      <td>134916.468750</td>\n",
       "      <td>330083.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>178000.0</td>\n",
       "      <td>59439.832031</td>\n",
       "      <td>118560.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>186500.0</td>\n",
       "      <td>67534.617188</td>\n",
       "      <td>118965.382812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>129500.0</td>\n",
       "      <td>51341.312500</td>\n",
       "      <td>78158.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>119000.0</td>\n",
       "      <td>1361.188965</td>\n",
       "      <td>117638.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>244000.0</td>\n",
       "      <td>69381.320312</td>\n",
       "      <td>174618.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>7018.016602</td>\n",
       "      <td>122981.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>165400.0</td>\n",
       "      <td>60559.246094</td>\n",
       "      <td>104840.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>127500.0</td>\n",
       "      <td>6650.645508</td>\n",
       "      <td>120849.351562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>301500.0</td>\n",
       "      <td>108523.007812</td>\n",
       "      <td>192977.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>99900.0</td>\n",
       "      <td>-17458.748047</td>\n",
       "      <td>117358.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>36036.171875</td>\n",
       "      <td>153963.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>151000.0</td>\n",
       "      <td>17602.767578</td>\n",
       "      <td>133397.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>128900.0</td>\n",
       "      <td>20835.380859</td>\n",
       "      <td>108064.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>180500.0</td>\n",
       "      <td>42587.617188</td>\n",
       "      <td>137912.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>181000.0</td>\n",
       "      <td>44995.019531</td>\n",
       "      <td>136004.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>183900.0</td>\n",
       "      <td>22514.753906</td>\n",
       "      <td>161385.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>122000.0</td>\n",
       "      <td>33420.460938</td>\n",
       "      <td>88579.539062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>378500.0</td>\n",
       "      <td>140812.437500</td>\n",
       "      <td>237687.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>144000.0</td>\n",
       "      <td>29777.138672</td>\n",
       "      <td>114222.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>177000.0</td>\n",
       "      <td>30132.373047</td>\n",
       "      <td>146867.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>139000.0</td>\n",
       "      <td>14845.348633</td>\n",
       "      <td>124154.648438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>137000.0</td>\n",
       "      <td>29824.005859</td>\n",
       "      <td>107175.992188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>237000.0</td>\n",
       "      <td>78960.500000</td>\n",
       "      <td>158039.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>68400.0</td>\n",
       "      <td>-9833.484375</td>\n",
       "      <td>78233.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>227000.0</td>\n",
       "      <td>64645.859375</td>\n",
       "      <td>162354.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>34760.554688</td>\n",
       "      <td>145239.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>150500.0</td>\n",
       "      <td>24888.824219</td>\n",
       "      <td>125611.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>139000.0</td>\n",
       "      <td>40555.304688</td>\n",
       "      <td>98444.695312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>169000.0</td>\n",
       "      <td>54472.546875</td>\n",
       "      <td>114527.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>132500.0</td>\n",
       "      <td>13242.732422</td>\n",
       "      <td>119257.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>278000.0</td>\n",
       "      <td>96044.468750</td>\n",
       "      <td>181955.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>281000.0</td>\n",
       "      <td>86305.695312</td>\n",
       "      <td>194694.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>119500.0</td>\n",
       "      <td>-11383.696289</td>\n",
       "      <td>130883.695312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>107500.0</td>\n",
       "      <td>36946.445312</td>\n",
       "      <td>70553.554688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>162900.0</td>\n",
       "      <td>30863.419922</td>\n",
       "      <td>132036.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>2066.833008</td>\n",
       "      <td>112933.164062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>138500.0</td>\n",
       "      <td>16209.049805</td>\n",
       "      <td>122290.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>20297.568359</td>\n",
       "      <td>134702.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>28577.896484</td>\n",
       "      <td>111422.101562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>335882.562500</td>\n",
       "      <td>-175882.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>154000.0</td>\n",
       "      <td>19043.560547</td>\n",
       "      <td>134956.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>290000.0</td>\n",
       "      <td>132606.312500</td>\n",
       "      <td>157393.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>232000.0</td>\n",
       "      <td>70539.656250</td>\n",
       "      <td>161460.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>20601.550781</td>\n",
       "      <td>109398.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>80396.679688</td>\n",
       "      <td>244603.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>44588.312500</td>\n",
       "      <td>157911.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>138000.0</td>\n",
       "      <td>19299.253906</td>\n",
       "      <td>118700.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>147000.0</td>\n",
       "      <td>10736.645508</td>\n",
       "      <td>136263.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>335000.0</td>\n",
       "      <td>58686.921875</td>\n",
       "      <td>276313.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>203000.0</td>\n",
       "      <td>39130.679688</td>\n",
       "      <td>163869.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>333168.0</td>\n",
       "      <td>160087.750000</td>\n",
       "      <td>173080.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>119000.0</td>\n",
       "      <td>4954.502441</td>\n",
       "      <td>114045.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>206900.0</td>\n",
       "      <td>64940.515625</td>\n",
       "      <td>141959.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>295493.0</td>\n",
       "      <td>85672.757812</td>\n",
       "      <td>209820.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>208900.0</td>\n",
       "      <td>61896.886719</td>\n",
       "      <td>147003.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>111000.0</td>\n",
       "      <td>17178.859375</td>\n",
       "      <td>93821.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>156500.0</td>\n",
       "      <td>35154.125000</td>\n",
       "      <td>121345.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>66109.937500</td>\n",
       "      <td>123890.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>82500.0</td>\n",
       "      <td>-22265.208984</td>\n",
       "      <td>104765.210938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>147000.0</td>\n",
       "      <td>72411.617188</td>\n",
       "      <td>74588.382812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>-21014.810547</td>\n",
       "      <td>76014.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>-10160.446289</td>\n",
       "      <td>89160.445312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>130500.0</td>\n",
       "      <td>8000.971680</td>\n",
       "      <td>122499.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>256000.0</td>\n",
       "      <td>73808.476562</td>\n",
       "      <td>182191.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>176500.0</td>\n",
       "      <td>57670.910156</td>\n",
       "      <td>118829.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>227000.0</td>\n",
       "      <td>58026.777344</td>\n",
       "      <td>168973.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>132500.0</td>\n",
       "      <td>20204.765625</td>\n",
       "      <td>112295.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1242.295776</td>\n",
       "      <td>98757.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>125500.0</td>\n",
       "      <td>13710.151367</td>\n",
       "      <td>111789.851562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>9082.271484</td>\n",
       "      <td>115917.726562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>167900.0</td>\n",
       "      <td>29311.435547</td>\n",
       "      <td>138588.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>27239.845703</td>\n",
       "      <td>107760.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>-13792.229492</td>\n",
       "      <td>66292.226562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>74790.140625</td>\n",
       "      <td>125209.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>128500.0</td>\n",
       "      <td>3512.956787</td>\n",
       "      <td>124987.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>123000.0</td>\n",
       "      <td>20452.470703</td>\n",
       "      <td>102547.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>35188.265625</td>\n",
       "      <td>119811.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>177000.0</td>\n",
       "      <td>32219.455078</td>\n",
       "      <td>144780.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>155835.0</td>\n",
       "      <td>46708.679688</td>\n",
       "      <td>109126.320312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>108500.0</td>\n",
       "      <td>-10759.984375</td>\n",
       "      <td>119259.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>283463.0</td>\n",
       "      <td>93806.148438</td>\n",
       "      <td>189656.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>122000.0</td>\n",
       "      <td>23570.251953</td>\n",
       "      <td>98429.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>59230.835938</td>\n",
       "      <td>140769.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>37463.515625</td>\n",
       "      <td>133536.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>134900.0</td>\n",
       "      <td>2552.225830</td>\n",
       "      <td>132347.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>410000.0</td>\n",
       "      <td>188603.125000</td>\n",
       "      <td>221396.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>51703.570312</td>\n",
       "      <td>118296.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>118953.140625</td>\n",
       "      <td>196046.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>189000.0</td>\n",
       "      <td>88090.679688</td>\n",
       "      <td>100909.320312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>260000.0</td>\n",
       "      <td>63552.906250</td>\n",
       "      <td>196447.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>156932.0</td>\n",
       "      <td>40424.367188</td>\n",
       "      <td>116507.632812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>144152.0</td>\n",
       "      <td>28186.931641</td>\n",
       "      <td>115965.070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>193000.0</td>\n",
       "      <td>66951.445312</td>\n",
       "      <td>126048.554688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>127000.0</td>\n",
       "      <td>15907.436523</td>\n",
       "      <td>111092.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>232000.0</td>\n",
       "      <td>77398.320312</td>\n",
       "      <td>154601.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>18926.095703</td>\n",
       "      <td>86073.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>165500.0</td>\n",
       "      <td>42154.769531</td>\n",
       "      <td>123345.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>274300.0</td>\n",
       "      <td>97476.312500</td>\n",
       "      <td>176823.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>97885.789062</td>\n",
       "      <td>152114.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>239000.0</td>\n",
       "      <td>84299.539062</td>\n",
       "      <td>154700.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>91000.0</td>\n",
       "      <td>-8246.063477</td>\n",
       "      <td>99246.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>31606.269531</td>\n",
       "      <td>85393.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>1380.303711</td>\n",
       "      <td>81619.695312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>167500.0</td>\n",
       "      <td>34226.414062</td>\n",
       "      <td>133273.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>58500.0</td>\n",
       "      <td>-18716.888672</td>\n",
       "      <td>77216.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>157000.0</td>\n",
       "      <td>29431.003906</td>\n",
       "      <td>127569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>19193.869141</td>\n",
       "      <td>85806.132812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>125500.0</td>\n",
       "      <td>1575.058960</td>\n",
       "      <td>123924.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>108425.328125</td>\n",
       "      <td>141574.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>136000.0</td>\n",
       "      <td>54481.859375</td>\n",
       "      <td>81518.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>377500.0</td>\n",
       "      <td>99363.898438</td>\n",
       "      <td>278136.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>131000.0</td>\n",
       "      <td>6268.184570</td>\n",
       "      <td>124731.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>235000.0</td>\n",
       "      <td>77749.171875</td>\n",
       "      <td>157250.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>124000.0</td>\n",
       "      <td>17691.732422</td>\n",
       "      <td>106308.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>123000.0</td>\n",
       "      <td>11605.541016</td>\n",
       "      <td>111394.460938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>163000.0</td>\n",
       "      <td>34394.378906</td>\n",
       "      <td>128605.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>246578.0</td>\n",
       "      <td>61720.460938</td>\n",
       "      <td>184857.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>281213.0</td>\n",
       "      <td>159101.312500</td>\n",
       "      <td>122111.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>137500.0</td>\n",
       "      <td>7851.105469</td>\n",
       "      <td>129648.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>138000.0</td>\n",
       "      <td>43890.140625</td>\n",
       "      <td>94109.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>137450.0</td>\n",
       "      <td>28504.132812</td>\n",
       "      <td>108945.867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>-2999.978760</td>\n",
       "      <td>122999.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>193000.0</td>\n",
       "      <td>61219.238281</td>\n",
       "      <td>131780.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>193879.0</td>\n",
       "      <td>47982.242188</td>\n",
       "      <td>145896.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>282922.0</td>\n",
       "      <td>58793.496094</td>\n",
       "      <td>224128.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>7378.702637</td>\n",
       "      <td>97621.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>69670.132812</td>\n",
       "      <td>205329.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>133000.0</td>\n",
       "      <td>4193.264648</td>\n",
       "      <td>128806.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>125500.0</td>\n",
       "      <td>3728.716309</td>\n",
       "      <td>121771.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>215000.0</td>\n",
       "      <td>97695.867188</td>\n",
       "      <td>117304.132812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>82893.265625</td>\n",
       "      <td>147106.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>33858.464844</td>\n",
       "      <td>106141.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>11821.721680</td>\n",
       "      <td>78178.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>257000.0</td>\n",
       "      <td>56916.046875</td>\n",
       "      <td>200083.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>44483.023438</td>\n",
       "      <td>162516.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>175900.0</td>\n",
       "      <td>62294.105469</td>\n",
       "      <td>113605.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>122500.0</td>\n",
       "      <td>25003.486328</td>\n",
       "      <td>97496.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>124000.0</td>\n",
       "      <td>13647.666992</td>\n",
       "      <td>110352.335938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>179900.0</td>\n",
       "      <td>33842.097656</td>\n",
       "      <td>146057.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>127500.0</td>\n",
       "      <td>11711.229492</td>\n",
       "      <td>115788.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>136500.0</td>\n",
       "      <td>12127.262695</td>\n",
       "      <td>124372.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>142000.0</td>\n",
       "      <td>30290.107422</td>\n",
       "      <td>111709.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>271000.0</td>\n",
       "      <td>87337.523438</td>\n",
       "      <td>183662.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>38744.769531</td>\n",
       "      <td>101255.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>119000.0</td>\n",
       "      <td>592.697083</td>\n",
       "      <td>118407.304688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>192140.0</td>\n",
       "      <td>104183.945312</td>\n",
       "      <td>87956.054688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>64500.0</td>\n",
       "      <td>8222.703125</td>\n",
       "      <td>56277.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>186500.0</td>\n",
       "      <td>77268.382812</td>\n",
       "      <td>109231.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>55704.050781</td>\n",
       "      <td>104295.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>174000.0</td>\n",
       "      <td>23067.205078</td>\n",
       "      <td>150932.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>120500.0</td>\n",
       "      <td>13871.122070</td>\n",
       "      <td>106628.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>394617.0</td>\n",
       "      <td>101738.070312</td>\n",
       "      <td>292878.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>149700.0</td>\n",
       "      <td>19587.056641</td>\n",
       "      <td>130112.945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>197000.0</td>\n",
       "      <td>46884.750000</td>\n",
       "      <td>150115.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>191000.0</td>\n",
       "      <td>65061.273438</td>\n",
       "      <td>125938.726562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>310000.0</td>\n",
       "      <td>83598.914062</td>\n",
       "      <td>226401.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>179600.0</td>\n",
       "      <td>56955.937500</td>\n",
       "      <td>122644.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>14318.348633</td>\n",
       "      <td>114681.648438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>240000.0</td>\n",
       "      <td>81389.148438</td>\n",
       "      <td>158610.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>4502.773926</td>\n",
       "      <td>107497.226562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>92000.0</td>\n",
       "      <td>-20170.337891</td>\n",
       "      <td>112170.335938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>136000.0</td>\n",
       "      <td>37130.742188</td>\n",
       "      <td>98869.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>287090.0</td>\n",
       "      <td>77051.445312</td>\n",
       "      <td>210038.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>19156.197266</td>\n",
       "      <td>125843.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>84500.0</td>\n",
       "      <td>57993.117188</td>\n",
       "      <td>26506.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>42551.398438</td>\n",
       "      <td>142448.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>68261.828125</td>\n",
       "      <td>106738.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>76840.945312</td>\n",
       "      <td>133159.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>266500.0</td>\n",
       "      <td>82693.070312</td>\n",
       "      <td>183806.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>142125.0</td>\n",
       "      <td>13918.916016</td>\n",
       "      <td>128206.085938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>147500.0</td>\n",
       "      <td>22901.380859</td>\n",
       "      <td>124598.617188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual    Predictions     Difference\n",
       "0    130000.0   30021.998047   99978.000000\n",
       "1    138887.0   46535.929688   92351.070312\n",
       "2    175500.0   30670.205078  144829.796875\n",
       "3    195000.0  109510.937500   85489.062500\n",
       "4    142500.0   45733.476562   96766.523438\n",
       "5    265900.0   58049.957031  207850.046875\n",
       "6    224900.0   71618.976562  153281.031250\n",
       "7    248328.0   84027.523438  164300.468750\n",
       "8    170000.0   33169.804688  136830.187500\n",
       "9    465000.0  134916.468750  330083.531250\n",
       "10   178000.0   59439.832031  118560.171875\n",
       "11   186500.0   67534.617188  118965.382812\n",
       "12   129500.0   51341.312500   78158.687500\n",
       "13   119000.0    1361.188965  117638.812500\n",
       "14   244000.0   69381.320312  174618.687500\n",
       "15   130000.0    7018.016602  122981.984375\n",
       "16   165400.0   60559.246094  104840.750000\n",
       "17   127500.0    6650.645508  120849.351562\n",
       "18   301500.0  108523.007812  192977.000000\n",
       "19    99900.0  -17458.748047  117358.750000\n",
       "20   190000.0   36036.171875  153963.828125\n",
       "21   151000.0   17602.767578  133397.234375\n",
       "22   128900.0   20835.380859  108064.617188\n",
       "23   180500.0   42587.617188  137912.375000\n",
       "24   181000.0   44995.019531  136004.984375\n",
       "25   183900.0   22514.753906  161385.250000\n",
       "26   122000.0   33420.460938   88579.539062\n",
       "27   378500.0  140812.437500  237687.562500\n",
       "28   144000.0   29777.138672  114222.859375\n",
       "29   177000.0   30132.373047  146867.625000\n",
       "30   139000.0   14845.348633  124154.648438\n",
       "31   137000.0   29824.005859  107175.992188\n",
       "32   237000.0   78960.500000  158039.500000\n",
       "33    68400.0   -9833.484375   78233.484375\n",
       "34   227000.0   64645.859375  162354.140625\n",
       "35   180000.0   34760.554688  145239.437500\n",
       "36   150500.0   24888.824219  125611.171875\n",
       "37   139000.0   40555.304688   98444.695312\n",
       "38   169000.0   54472.546875  114527.453125\n",
       "39   132500.0   13242.732422  119257.265625\n",
       "40   278000.0   96044.468750  181955.531250\n",
       "41   281000.0   86305.695312  194694.312500\n",
       "42   119500.0  -11383.696289  130883.695312\n",
       "43   107500.0   36946.445312   70553.554688\n",
       "44   162900.0   30863.419922  132036.578125\n",
       "45   115000.0    2066.833008  112933.164062\n",
       "46   138500.0   16209.049805  122290.953125\n",
       "47   155000.0   20297.568359  134702.437500\n",
       "48   140000.0   28577.896484  111422.101562\n",
       "49   160000.0  335882.562500 -175882.562500\n",
       "50   154000.0   19043.560547  134956.437500\n",
       "51   290000.0  132606.312500  157393.687500\n",
       "52   232000.0   70539.656250  161460.343750\n",
       "53   130000.0   20601.550781  109398.453125\n",
       "54   325000.0   80396.679688  244603.312500\n",
       "55   202500.0   44588.312500  157911.687500\n",
       "56   138000.0   19299.253906  118700.750000\n",
       "57   147000.0   10736.645508  136263.359375\n",
       "58   335000.0   58686.921875  276313.062500\n",
       "59   203000.0   39130.679688  163869.312500\n",
       "60   333168.0  160087.750000  173080.250000\n",
       "61   119000.0    4954.502441  114045.500000\n",
       "62   206900.0   64940.515625  141959.484375\n",
       "63   295493.0   85672.757812  209820.250000\n",
       "64   208900.0   61896.886719  147003.109375\n",
       "65   111000.0   17178.859375   93821.140625\n",
       "66   156500.0   35154.125000  121345.875000\n",
       "67   190000.0   66109.937500  123890.062500\n",
       "68    82500.0  -22265.208984  104765.210938\n",
       "69   147000.0   72411.617188   74588.382812\n",
       "70    55000.0  -21014.810547   76014.812500\n",
       "71    79000.0  -10160.446289   89160.445312\n",
       "72   130500.0    8000.971680  122499.031250\n",
       "73   256000.0   73808.476562  182191.531250\n",
       "74   176500.0   57670.910156  118829.093750\n",
       "75   227000.0   58026.777344  168973.218750\n",
       "76   132500.0   20204.765625  112295.234375\n",
       "77   100000.0    1242.295776   98757.703125\n",
       "78   125500.0   13710.151367  111789.851562\n",
       "79   125000.0    9082.271484  115917.726562\n",
       "80   167900.0   29311.435547  138588.562500\n",
       "81   135000.0   27239.845703  107760.156250\n",
       "82    52500.0  -13792.229492   66292.226562\n",
       "83   200000.0   74790.140625  125209.859375\n",
       "84   128500.0    3512.956787  124987.046875\n",
       "85   123000.0   20452.470703  102547.531250\n",
       "86   155000.0   35188.265625  119811.734375\n",
       "87   177000.0   32219.455078  144780.546875\n",
       "88   155835.0   46708.679688  109126.320312\n",
       "89   108500.0  -10759.984375  119259.984375\n",
       "90   283463.0   93806.148438  189656.843750\n",
       "91   122000.0   23570.251953   98429.750000\n",
       "92   200000.0   59230.835938  140769.156250\n",
       "93   171000.0   37463.515625  133536.484375\n",
       "94   134900.0    2552.225830  132347.781250\n",
       "95   410000.0  188603.125000  221396.875000\n",
       "96   170000.0   51703.570312  118296.429688\n",
       "97   315000.0  118953.140625  196046.859375\n",
       "98   189000.0   88090.679688  100909.320312\n",
       "99   260000.0   63552.906250  196447.093750\n",
       "100  156932.0   40424.367188  116507.632812\n",
       "101  144152.0   28186.931641  115965.070312\n",
       "102  193000.0   66951.445312  126048.554688\n",
       "103  127000.0   15907.436523  111092.562500\n",
       "104  232000.0   77398.320312  154601.687500\n",
       "105  105000.0   18926.095703   86073.906250\n",
       "106  165500.0   42154.769531  123345.234375\n",
       "107  274300.0   97476.312500  176823.687500\n",
       "108  250000.0   97885.789062  152114.218750\n",
       "109  239000.0   84299.539062  154700.468750\n",
       "110   91000.0   -8246.063477   99246.062500\n",
       "111  117000.0   31606.269531   85393.734375\n",
       "112   83000.0    1380.303711   81619.695312\n",
       "113  167500.0   34226.414062  133273.593750\n",
       "114   58500.0  -18716.888672   77216.890625\n",
       "115  157000.0   29431.003906  127569.000000\n",
       "116  105000.0   19193.869141   85806.132812\n",
       "117  125500.0    1575.058960  123924.937500\n",
       "118  250000.0  108425.328125  141574.671875\n",
       "119  136000.0   54481.859375   81518.140625\n",
       "120  377500.0   99363.898438  278136.093750\n",
       "121  131000.0    6268.184570  124731.812500\n",
       "122  235000.0   77749.171875  157250.828125\n",
       "123  124000.0   17691.732422  106308.265625\n",
       "124  123000.0   11605.541016  111394.460938\n",
       "125  163000.0   34394.378906  128605.625000\n",
       "126  246578.0   61720.460938  184857.531250\n",
       "127  281213.0  159101.312500  122111.687500\n",
       "128  137500.0    7851.105469  129648.890625\n",
       "129  138000.0   43890.140625   94109.859375\n",
       "130  137450.0   28504.132812  108945.867188\n",
       "131  120000.0   -2999.978760  122999.976562\n",
       "132  193000.0   61219.238281  131780.765625\n",
       "133  193879.0   47982.242188  145896.750000\n",
       "134  282922.0   58793.496094  224128.500000\n",
       "135  105000.0    7378.702637   97621.296875\n",
       "136  275000.0   69670.132812  205329.875000\n",
       "137  133000.0    4193.264648  128806.734375\n",
       "138  125500.0    3728.716309  121771.281250\n",
       "139  215000.0   97695.867188  117304.132812\n",
       "140  230000.0   82893.265625  147106.734375\n",
       "141  140000.0   33858.464844  106141.531250\n",
       "142   90000.0   11821.721680   78178.281250\n",
       "143  257000.0   56916.046875  200083.953125\n",
       "144  207000.0   44483.023438  162516.968750\n",
       "145  175900.0   62294.105469  113605.890625\n",
       "146  122500.0   25003.486328   97496.515625\n",
       "147  124000.0   13647.666992  110352.335938\n",
       "148  179900.0   33842.097656  146057.906250\n",
       "149  127500.0   11711.229492  115788.773438\n",
       "150  136500.0   12127.262695  124372.734375\n",
       "151  142000.0   30290.107422  111709.890625\n",
       "152  271000.0   87337.523438  183662.468750\n",
       "153  140000.0   38744.769531  101255.234375\n",
       "154  119000.0     592.697083  118407.304688\n",
       "155  192140.0  104183.945312   87956.054688\n",
       "156   64500.0    8222.703125   56277.296875\n",
       "157  186500.0   77268.382812  109231.617188\n",
       "158  160000.0   55704.050781  104295.953125\n",
       "159  174000.0   23067.205078  150932.796875\n",
       "160  120500.0   13871.122070  106628.875000\n",
       "161  394617.0  101738.070312  292878.937500\n",
       "162  149700.0   19587.056641  130112.945312\n",
       "163  197000.0   46884.750000  150115.250000\n",
       "164  191000.0   65061.273438  125938.726562\n",
       "165  310000.0   83598.914062  226401.093750\n",
       "166  179600.0   56955.937500  122644.062500\n",
       "167  129000.0   14318.348633  114681.648438\n",
       "168  240000.0   81389.148438  158610.843750\n",
       "169  112000.0    4502.773926  107497.226562\n",
       "170   92000.0  -20170.337891  112170.335938\n",
       "171  136000.0   37130.742188   98869.257812\n",
       "172  287090.0   77051.445312  210038.562500\n",
       "173  145000.0   19156.197266  125843.804688\n",
       "174   84500.0   57993.117188   26506.882812\n",
       "175  185000.0   42551.398438  142448.593750\n",
       "176  175000.0   68261.828125  106738.171875\n",
       "177  210000.0   76840.945312  133159.062500\n",
       "178  266500.0   82693.070312  183806.937500\n",
       "179  142125.0   13918.916016  128206.085938\n",
       "180  147500.0   22901.380859  124598.617188"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Actual = pd.DataFrame(y_test.numpy(),columns=['Actual'])\n",
    "Predicted = pd.DataFrame(y_pred.numpy(),columns=['Predictions'])\n",
    "Final = pd.concat([Actual,Predicted],axis=1)\n",
    "Final['Difference'] = Final['Actual']-Final['Predictions']\n",
    "Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sid/.local/lib/python3.6/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type FeedForwardNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "#### Saving The Model\n",
    "#### Save the model\n",
    "torch.save(model,'HousePrice.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'HouseWeights.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the saved Model\n",
    "embs_size=[(15, 8), (5, 3), (2, 1), (4, 2)]\n",
    "model1=FeedForwardNN(embs_size,5,1,[100,50],p=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_state_dict(torch.load('HouseWeights.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardNN(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(15, 8)\n",
       "    (1): Embedding(5, 3)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(4, 2)\n",
       "  )\n",
       "  (embed_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=19, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
