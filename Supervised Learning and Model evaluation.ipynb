{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer.keys():\n",
      " dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer(as_frame=True)\n",
    "print(\"cancer.keys():\\n\", cancer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U23')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.feature_names.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.feature_names =cancer.feature_names.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U23')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.feature_names.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([cancer.data,pd.DataFrame(cancer.target)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      "mean radius                569 non-null float64\n",
      "mean texture               569 non-null float64\n",
      "mean perimeter             569 non-null float64\n",
      "mean area                  569 non-null float64\n",
      "mean smoothness            569 non-null float64\n",
      "mean compactness           569 non-null float64\n",
      "mean concavity             569 non-null float64\n",
      "mean concave points        569 non-null float64\n",
      "mean symmetry              569 non-null float64\n",
      "mean fractal dimension     569 non-null float64\n",
      "radius error               569 non-null float64\n",
      "texture error              569 non-null float64\n",
      "perimeter error            569 non-null float64\n",
      "area error                 569 non-null float64\n",
      "smoothness error           569 non-null float64\n",
      "compactness error          569 non-null float64\n",
      "concavity error            569 non-null float64\n",
      "concave points error       569 non-null float64\n",
      "symmetry error             569 non-null float64\n",
      "fractal dimension error    569 non-null float64\n",
      "worst radius               569 non-null float64\n",
      "worst texture              569 non-null float64\n",
      "worst perimeter            569 non-null float64\n",
      "worst area                 569 non-null float64\n",
      "worst smoothness           569 non-null float64\n",
      "worst compactness          569 non-null float64\n",
      "worst concavity            569 non-null float64\n",
      "worst concave points       569 non-null float64\n",
      "worst symmetry             569 non-null float64\n",
      "worst fractal dimension    569 non-null float64\n",
      "target                     569 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension      target  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer.data\n",
    "y = cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1,random_state = 1)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"accuracy: \", knn.score(X_test, y_test))\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threefold Split for Hyper-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For finding best hyper-parameter what we did was further split X_train into X_train and X_val so X_val was used to find the best parameters and test data was used at last to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation score: 0.925\n",
      "best n_neighbors: 3\n",
      "test-set score: 0.902\n"
     ]
    }
   ],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval)\n",
    "val_scores = []\n",
    "neighbors = np.arange(1, 15, 2)\n",
    "for i in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i,random_state=1)\n",
    "    knn.fit(X_train, y_train)\n",
    "    val_scores.append(knn.score(X_val, y_val))\n",
    "print(f\"best validation score: {np.max(val_scores):.3}\")\n",
    "best_n_neighbors = neighbors[np.argmax(val_scores)]\n",
    "print(\"best n_neighbors:\", best_n_neighbors)\n",
    "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
    "knn.fit(X_trainval, y_trainval)\n",
    "print(f\"test-set score: {knn.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After finding best parameter further it was fitted to the value with best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search with Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, instead of spliting training data we do cross validation on training data, however test data is still kept aside for model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cross-validation score: 0.937\n",
      "best n_neighbors: 11\n",
      "test-set score: 0.937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "cross_val_scores = []\n",
    "for i in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10)\n",
    "    cross_val_scores.append(np.mean(scores))\n",
    "print(f\"best cross-validation score: {np.max(cross_val_scores):.3}\")\n",
    "best_n_neighbors = neighbors[np.argmax(cross_val_scores)]\n",
    "print(f\"best n_neighbors: {best_n_neighbors}\")\n",
    "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "print(f\"test-set score: {knn.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.9297342192691029\n",
      "best parameters: {'n_neighbors': 9}\n",
      "test-set score: 0.951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "param_grid = {'n_neighbors':  np.arange(1, 30, 2)}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=10,\n",
    "                   return_train_score=True)\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"best mean cross-validation score: {grid.best_score_}\")\n",
    "print(f\"best parameters: {grid.best_params_}\")\n",
    "print(f\"test-set score: {grid.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_n_neighbors', 'params', 'split0_test_score', 'split1_test_score',\n",
       "       'split2_test_score', 'split3_test_score', 'split4_test_score',\n",
       "       'split5_test_score', 'split6_test_score', 'split7_test_score',\n",
       "       'split8_test_score', 'split9_test_score', 'mean_test_score',\n",
       "       'std_test_score', 'rank_test_score', 'split0_train_score',\n",
       "       'split1_train_score', 'split2_train_score', 'split3_train_score',\n",
       "       'split4_train_score', 'split5_train_score', 'split6_train_score',\n",
       "       'split7_train_score', 'split8_train_score', 'split9_train_score',\n",
       "       'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _ at last means calculation is carried out on data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      {'n_neighbors': 1}\n",
       "1      {'n_neighbors': 3}\n",
       "2      {'n_neighbors': 5}\n",
       "3      {'n_neighbors': 7}\n",
       "4      {'n_neighbors': 9}\n",
       "5     {'n_neighbors': 11}\n",
       "6     {'n_neighbors': 13}\n",
       "7     {'n_neighbors': 15}\n",
       "8     {'n_neighbors': 17}\n",
       "9     {'n_neighbors': 19}\n",
       "10    {'n_neighbors': 21}\n",
       "11    {'n_neighbors': 23}\n",
       "12    {'n_neighbors': 25}\n",
       "13    {'n_neighbors': 27}\n",
       "14    {'n_neighbors': 29}\n",
       "Name: params, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.004121</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942559</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.942559</td>\n",
       "      <td>0.947781</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.946008</td>\n",
       "      <td>0.005109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929504</td>\n",
       "      <td>0.926893</td>\n",
       "      <td>0.929504</td>\n",
       "      <td>0.947781</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>0.934896</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.933751</td>\n",
       "      <td>0.005620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937337</td>\n",
       "      <td>0.932115</td>\n",
       "      <td>0.932115</td>\n",
       "      <td>0.947781</td>\n",
       "      <td>0.934896</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>0.934796</td>\n",
       "      <td>0.004927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.004480</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934726</td>\n",
       "      <td>0.934726</td>\n",
       "      <td>0.937337</td>\n",
       "      <td>0.942559</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.934896</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.936358</td>\n",
       "      <td>0.003142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>11</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929504</td>\n",
       "      <td>0.934726</td>\n",
       "      <td>0.932115</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.934896</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>0.931666</td>\n",
       "      <td>0.004453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>13</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924282</td>\n",
       "      <td>0.929504</td>\n",
       "      <td>0.929504</td>\n",
       "      <td>0.934726</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>0.924479</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>0.927750</td>\n",
       "      <td>0.004848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924282</td>\n",
       "      <td>0.926893</td>\n",
       "      <td>0.929504</td>\n",
       "      <td>0.932115</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.924479</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.926446</td>\n",
       "      <td>0.003860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>17</td>\n",
       "      <td>{'n_neighbors': 17}</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921671</td>\n",
       "      <td>0.919060</td>\n",
       "      <td>0.921671</td>\n",
       "      <td>0.926893</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.924479</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.923316</td>\n",
       "      <td>0.003366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>19</td>\n",
       "      <td>{'n_neighbors': 19}</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921671</td>\n",
       "      <td>0.913838</td>\n",
       "      <td>0.916449</td>\n",
       "      <td>0.924282</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.919271</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.919271</td>\n",
       "      <td>0.919667</td>\n",
       "      <td>0.003248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>21</td>\n",
       "      <td>{'n_neighbors': 21}</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919060</td>\n",
       "      <td>0.916449</td>\n",
       "      <td>0.913838</td>\n",
       "      <td>0.924282</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.918103</td>\n",
       "      <td>0.003871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.004927</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>23</td>\n",
       "      <td>{'n_neighbors': 23}</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916449</td>\n",
       "      <td>0.913838</td>\n",
       "      <td>0.911227</td>\n",
       "      <td>0.921671</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.911458</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.911458</td>\n",
       "      <td>0.915495</td>\n",
       "      <td>0.003675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>25</td>\n",
       "      <td>{'n_neighbors': 25}</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916449</td>\n",
       "      <td>0.911227</td>\n",
       "      <td>0.911227</td>\n",
       "      <td>0.921671</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.908854</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.911458</td>\n",
       "      <td>0.914974</td>\n",
       "      <td>0.004025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>27</td>\n",
       "      <td>{'n_neighbors': 27}</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916449</td>\n",
       "      <td>0.908616</td>\n",
       "      <td>0.913838</td>\n",
       "      <td>0.921671</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.908854</td>\n",
       "      <td>0.911458</td>\n",
       "      <td>0.911458</td>\n",
       "      <td>0.914713</td>\n",
       "      <td>0.004318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>29</td>\n",
       "      <td>{'n_neighbors': 29}</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916449</td>\n",
       "      <td>0.908616</td>\n",
       "      <td>0.908616</td>\n",
       "      <td>0.921671</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.911458</td>\n",
       "      <td>0.911458</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.914451</td>\n",
       "      <td>0.004152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.004121      0.000812         0.004669        0.000870   \n",
       "1        0.003799      0.000071         0.004286        0.000198   \n",
       "2        0.003978      0.000424         0.004312        0.000222   \n",
       "3        0.004299      0.000769         0.004262        0.000050   \n",
       "4        0.004508      0.000932         0.004480        0.000375   \n",
       "5        0.003810      0.000123         0.004455        0.000330   \n",
       "6        0.003738      0.000258         0.004431        0.000460   \n",
       "7        0.003612      0.000065         0.004208        0.000297   \n",
       "8        0.003831      0.000454         0.004248        0.000211   \n",
       "9        0.003639      0.000084         0.004394        0.000438   \n",
       "10       0.004939      0.002371         0.006107        0.002662   \n",
       "11       0.004157      0.000600         0.004927        0.000853   \n",
       "12       0.003768      0.000057         0.004620        0.000257   \n",
       "13       0.005069      0.002027         0.006430        0.003064   \n",
       "14       0.003923      0.000162         0.004630        0.000148   \n",
       "\n",
       "   param_n_neighbors               params  split0_test_score  \\\n",
       "0                  1   {'n_neighbors': 1}           0.883721   \n",
       "1                  3   {'n_neighbors': 3}           0.906977   \n",
       "2                  5   {'n_neighbors': 5}           0.860465   \n",
       "3                  7   {'n_neighbors': 7}           0.906977   \n",
       "4                  9   {'n_neighbors': 9}           0.930233   \n",
       "5                 11  {'n_neighbors': 11}           0.930233   \n",
       "6                 13  {'n_neighbors': 13}           0.883721   \n",
       "7                 15  {'n_neighbors': 15}           0.883721   \n",
       "8                 17  {'n_neighbors': 17}           0.883721   \n",
       "9                 19  {'n_neighbors': 19}           0.883721   \n",
       "10                21  {'n_neighbors': 21}           0.883721   \n",
       "11                23  {'n_neighbors': 23}           0.883721   \n",
       "12                25  {'n_neighbors': 25}           0.883721   \n",
       "13                27  {'n_neighbors': 27}           0.883721   \n",
       "14                29  {'n_neighbors': 29}           0.883721   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0            0.953488           0.930233           0.906977  ...   \n",
       "1            0.906977           0.930233           0.953488  ...   \n",
       "2            0.906977           0.953488           0.976744  ...   \n",
       "3            0.883721           0.906977           0.953488  ...   \n",
       "4            0.883721           0.930233           0.953488  ...   \n",
       "5            0.906977           0.906977           0.953488  ...   \n",
       "6            0.883721           0.906977           0.953488  ...   \n",
       "7            0.860465           0.906977           0.953488  ...   \n",
       "8            0.860465           0.906977           0.953488  ...   \n",
       "9            0.860465           0.906977           0.953488  ...   \n",
       "10           0.860465           0.883721           0.953488  ...   \n",
       "11           0.860465           0.906977           0.953488  ...   \n",
       "12           0.860465           0.883721           0.953488  ...   \n",
       "13           0.860465           0.883721           0.953488  ...   \n",
       "14           0.860465           0.883721           0.953488  ...   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             1.000000            1.000000            1.000000   \n",
       "1             0.942559            0.939948            0.942559   \n",
       "2             0.929504            0.926893            0.929504   \n",
       "3             0.937337            0.932115            0.932115   \n",
       "4             0.934726            0.934726            0.937337   \n",
       "5             0.929504            0.934726            0.932115   \n",
       "6             0.924282            0.929504            0.929504   \n",
       "7             0.924282            0.926893            0.929504   \n",
       "8             0.921671            0.919060            0.921671   \n",
       "9             0.921671            0.913838            0.916449   \n",
       "10            0.919060            0.916449            0.913838   \n",
       "11            0.916449            0.913838            0.911227   \n",
       "12            0.916449            0.911227            0.911227   \n",
       "13            0.916449            0.908616            0.913838   \n",
       "14            0.916449            0.908616            0.908616   \n",
       "\n",
       "    split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0             1.000000            1.000000            1.000000   \n",
       "1             0.947781            0.947917            0.947917   \n",
       "2             0.947781            0.937500            0.932292   \n",
       "3             0.947781            0.934896            0.932292   \n",
       "4             0.942559            0.937500            0.934896   \n",
       "5             0.939948            0.934896            0.921875   \n",
       "6             0.934726            0.932292            0.924479   \n",
       "7             0.932115            0.929688            0.927083   \n",
       "8             0.926893            0.929688            0.924479   \n",
       "9             0.924282            0.921875            0.919271   \n",
       "10            0.924282            0.921875            0.916667   \n",
       "11            0.921671            0.914062            0.911458   \n",
       "12            0.921671            0.916667            0.908854   \n",
       "13            0.921671            0.916667            0.908854   \n",
       "14            0.921671            0.916667            0.911458   \n",
       "\n",
       "    split8_train_score  split9_train_score  mean_train_score  std_train_score  \n",
       "0             1.000000            1.000000          1.000000         0.000000  \n",
       "1             0.945312            0.947917          0.946008         0.005109  \n",
       "2             0.934896            0.929688          0.933751         0.005620  \n",
       "3             0.932292            0.932292          0.934796         0.004927  \n",
       "4             0.937500            0.937500          0.936358         0.003142  \n",
       "5             0.929688            0.932292          0.931666         0.004453  \n",
       "6             0.929688            0.932292          0.927750         0.004848  \n",
       "7             0.924479            0.929688          0.926446         0.003860  \n",
       "8             0.921875            0.921875          0.923316         0.003366  \n",
       "9             0.916667            0.919271          0.919667         0.003248  \n",
       "10            0.914062            0.914062          0.918103         0.003871  \n",
       "11            0.916667            0.911458          0.915495         0.003675  \n",
       "12            0.914062            0.911458          0.914974         0.004025  \n",
       "13            0.911458            0.911458          0.914713         0.004318  \n",
       "14            0.911458            0.914062          0.914451         0.004152  \n",
       "\n",
       "[15 rows x 31 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1ae6f5f128>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results.param_n_neighbors,results.mean_train_score,label = 'Mean_train_score')\n",
    "plt.plot(results.param_n_neighbors,results.mean_test_score,label = 'Mean_test_score')\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('mean_score')\n",
    "plt.title('N_neighbors vs Mean_train/test_score')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested cross validation \n",
    "It means for train and test split as we use cros validation. But it requires lots of time and is not in practice for larger data however for short datasets we can still give it a try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type of cross validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold vs Stratified K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,KFold,StratifiedKFold\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy Classifier is just a random model which predicts randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DummyClassifier('most_frequent') #i.e. it always detects output to be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6274181027790716\n",
      "0.003948679172659169\n"
     ]
    }
   ],
   "source": [
    "stk = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "res = cross_val_score(dm,X,y,cv=stk)\n",
    "print(np.mean(res))\n",
    "print(res.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6273715261605342\n",
      "0.03582507393117649\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5 , shuffle= True)\n",
    "res1 = cross_val_score(dm,X,y,cv=kf)\n",
    "print(np.mean(res1))\n",
    "print(res1.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle must be done to avoid imbalanced dataset problem \n",
    "By Default:\n",
    "\n",
    "1. 5-fold in 0.22 (used to be 3 fold)\n",
    "2. For classification cross-validation is stratified\n",
    "3. train_test_split has stratify option: train_test_split(X, y, stratify=y)\n",
    "4. No shuffle by default!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle K-fold:\n",
    "\n",
    "They are better than k-fold as we know once our data is shuffle we split them into fold and each fold once becomes a test set i.e. no repeation of data in test sets.\n",
    "But here, for each iteration we do shuffling i.e. for iteration one we get our test set then before second iteration we again do shuffle with replacement it may lead to repeation of datas in test set. Here,we chose number of iteration and ratio of test split  so if iteration=1 it works as train_test_split. But this may increase variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit:\n",
      "[0.93567251 0.9005848  0.93567251 0.92982456 0.87719298 0.92982456\n",
      " 0.94152047 0.91812865 0.92982456 0.94152047 0.93567251 0.89473684\n",
      " 0.9005848  0.9122807  0.95321637 0.90643275 0.94736842 0.92397661\n",
      " 0.94736842 0.91812865]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "sh = ShuffleSplit(n_splits=20, train_size=.4, test_size=.3)\n",
    "\n",
    "print(\"ShuffleSplit:\")\n",
    "print(cross_val_score(KNeighborsClassifier(), X, y, cv=sh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It can be used better when we have to only use certain percentage of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated Stratified K-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is more advanced and better k-fold validation. Here for each iteration, stratified k-fold is done several time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepeatedStratifiedKFold:\n",
      "[0.9122807  0.92105263 0.92105263 0.95614035 0.94690265 0.94736842\n",
      " 0.92982456 0.96491228 0.92982456 0.90265487 0.93859649 0.93859649\n",
      " 0.89473684 0.94736842 0.92035398 0.92982456 0.93859649 0.93859649\n",
      " 0.94736842 0.91150442 0.89473684 0.92982456 0.96491228 0.92982456\n",
      " 0.92035398 0.92982456 0.94736842 0.93859649 0.88596491 0.97345133\n",
      " 0.9122807  0.9122807  0.96491228 0.92105263 0.95575221 0.97368421\n",
      " 0.92982456 0.92105263 0.92982456 0.90265487 0.93859649 0.9122807\n",
      " 0.90350877 0.92105263 0.95575221 0.94736842 0.90350877 0.9122807\n",
      " 0.94736842 0.97345133]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "rs = RepeatedStratifiedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "print(\"RepeatedStratifiedKFold:\")\n",
    "print(cross_val_score(KNeighborsClassifier(), X, y, cv=rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Group Kfold\n",
    "Suppose we have data of 5 cities pkr,ktm,brt,jhapa,birgunj. Now we have to predict future of people within those city i.e. independent and identically distributed example and can be done as above.\n",
    "\n",
    "But if we have to find for new city say dharan, we don't have data of dharan i.e. model won't predict for dharan as it hasn't seen dharan while on training. In this case GroupKFold is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Series Split\n",
    "Here, data are time  dependent so we can't directly shuffle and chose train and test data as all data are time dependent and if shuffles doesnt provide exact meaning. So, we train using past continous data and try testing by predicting future value. Here, if we dont give max_training data then, test_size will be all data after training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TimeSeriesSplit(5,max_train_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross_validate function\n",
    "It is similar to cross validation score but instead of only score it gives many data such as fit_time ,score_time and scoring metrics selected for both test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "res = cross_validate(KNeighborsClassifier(), X, y, return_train_score=True,\n",
    "                     scoring=[\"accuracy\", \"roc_auc\"])\n",
    "res_df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.112724</td>\n",
       "      <td>0.885965</td>\n",
       "      <td>0.951648</td>\n",
       "      <td>0.945955</td>\n",
       "      <td>0.991538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>0.013457</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.951648</td>\n",
       "      <td>0.952997</td>\n",
       "      <td>0.992355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.011018</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.947253</td>\n",
       "      <td>0.981151</td>\n",
       "      <td>0.990733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.011108</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.989680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>0.929204</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.955064</td>\n",
       "      <td>0.992112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy  test_roc_auc  \\\n",
       "0  0.005785    0.112724       0.885965        0.951648      0.945955   \n",
       "1  0.008845    0.013457       0.938596        0.951648      0.952997   \n",
       "2  0.003914    0.011018       0.938596        0.947253      0.981151   \n",
       "3  0.003840    0.011108       0.947368        0.938462      0.962963   \n",
       "4  0.003750    0.010496       0.929204        0.947368      0.955064   \n",
       "\n",
       "   train_roc_auc  \n",
       "0       0.991538  \n",
       "1       0.992355  \n",
       "2       0.990733  \n",
       "3       0.989680  \n",
       "4       0.992112  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
