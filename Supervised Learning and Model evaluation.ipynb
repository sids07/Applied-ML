{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer.keys():\n",
      " dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer(as_frame=True)\n",
    "print(\"cancer.keys():\\n\", cancer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U23')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.feature_names.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.feature_names =cancer.feature_names.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U23')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.feature_names.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([cancer.data,pd.DataFrame(cancer.target)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                  0.2654          0.4601                  0.11890       0  \n",
       "1                  0.1860          0.2750                  0.08902       0  \n",
       "2                  0.2430          0.3613                  0.08758       0  \n",
       "3                  0.2575          0.6638                  0.17300       0  \n",
       "4                  0.1625          0.2364                  0.07678       0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115       0  \n",
       "565                0.1628          0.2572                  0.06637       0  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      "mean radius                569 non-null float64\n",
      "mean texture               569 non-null float64\n",
      "mean perimeter             569 non-null float64\n",
      "mean area                  569 non-null float64\n",
      "mean smoothness            569 non-null float64\n",
      "mean compactness           569 non-null float64\n",
      "mean concavity             569 non-null float64\n",
      "mean concave points        569 non-null float64\n",
      "mean symmetry              569 non-null float64\n",
      "mean fractal dimension     569 non-null float64\n",
      "radius error               569 non-null float64\n",
      "texture error              569 non-null float64\n",
      "perimeter error            569 non-null float64\n",
      "area error                 569 non-null float64\n",
      "smoothness error           569 non-null float64\n",
      "compactness error          569 non-null float64\n",
      "concavity error            569 non-null float64\n",
      "concave points error       569 non-null float64\n",
      "symmetry error             569 non-null float64\n",
      "fractal dimension error    569 non-null float64\n",
      "worst radius               569 non-null float64\n",
      "worst texture              569 non-null float64\n",
      "worst perimeter            569 non-null float64\n",
      "worst area                 569 non-null float64\n",
      "worst smoothness           569 non-null float64\n",
      "worst compactness          569 non-null float64\n",
      "worst concavity            569 non-null float64\n",
      "worst concave points       569 non-null float64\n",
      "worst symmetry             569 non-null float64\n",
      "worst fractal dimension    569 non-null float64\n",
      "target                     569 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension      target  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer.data\n",
    "y = cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"accuracy: \", knn.score(X_test, y_test))\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threefold Split for Hyper-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For finding best hyper-parameter what we did was further split X_train into X_train and X_val so X_val was used to find the best parameters and test data was used at last to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation score: 0.953\n",
      "best n_neighbors: 5\n",
      "test-set score: 0.937\n"
     ]
    }
   ],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval)\n",
    "val_scores = []\n",
    "neighbors = np.arange(1, 15, 2)\n",
    "for i in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    val_scores.append(knn.score(X_val, y_val))\n",
    "print(f\"best validation score: {np.max(val_scores):.3}\")\n",
    "best_n_neighbors = neighbors[np.argmax(val_scores)]\n",
    "print(\"best n_neighbors:\", best_n_neighbors)\n",
    "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
    "knn.fit(X_trainval, y_trainval)\n",
    "print(f\"test-set score: {knn.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After finding best parameter further it was fitted to the value with best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search with Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, instead of spliting training data we do cross validation on training data, however test data is still kept aside for model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best cross-validation score: 0.927\n",
      "best n_neighbors: 7\n",
      "test-set score: 0.930\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "cross_val_scores = []\n",
    "for i in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10)\n",
    "    cross_val_scores.append(np.mean(scores))\n",
    "print(f\"best cross-validation score: {np.max(cross_val_scores):.3}\")\n",
    "best_n_neighbors = neighbors[np.argmax(cross_val_scores)]\n",
    "print(f\"best n_neighbors: {best_n_neighbors}\")\n",
    "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "print(f\"test-set score: {knn.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.9389258028792913\n",
      "best parameters: {'n_neighbors': 7}\n",
      "test-set score: 0.902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "param_grid = {'n_neighbors':  np.arange(1, 30, 2)}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=10,\n",
    "                   return_train_score=True)\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"best mean cross-validation score: {grid.best_score_}\")\n",
    "print(f\"best parameters: {grid.best_params_}\")\n",
    "print(f\"test-set score: {grid.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_n_neighbors', 'params', 'split0_test_score', 'split1_test_score',\n",
       "       'split2_test_score', 'split3_test_score', 'split4_test_score',\n",
       "       'split5_test_score', 'split6_test_score', 'split7_test_score',\n",
       "       'split8_test_score', 'split9_test_score', 'mean_test_score',\n",
       "       'std_test_score', 'rank_test_score', 'split0_train_score',\n",
       "       'split1_train_score', 'split2_train_score', 'split3_train_score',\n",
       "       'split4_train_score', 'split5_train_score', 'split6_train_score',\n",
       "       'split7_train_score', 'split8_train_score', 'split9_train_score',\n",
       "       'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _ at last means calculation is carried out on data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      {'n_neighbors': 1}\n",
       "1      {'n_neighbors': 3}\n",
       "2      {'n_neighbors': 5}\n",
       "3      {'n_neighbors': 7}\n",
       "4      {'n_neighbors': 9}\n",
       "5     {'n_neighbors': 11}\n",
       "6     {'n_neighbors': 13}\n",
       "7     {'n_neighbors': 15}\n",
       "8     {'n_neighbors': 17}\n",
       "9     {'n_neighbors': 19}\n",
       "10    {'n_neighbors': 21}\n",
       "11    {'n_neighbors': 23}\n",
       "12    {'n_neighbors': 25}\n",
       "13    {'n_neighbors': 27}\n",
       "14    {'n_neighbors': 29}\n",
       "Name: params, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966057</td>\n",
       "      <td>0.953003</td>\n",
       "      <td>0.960836</td>\n",
       "      <td>0.950392</td>\n",
       "      <td>0.955729</td>\n",
       "      <td>0.955729</td>\n",
       "      <td>0.963542</td>\n",
       "      <td>0.963542</td>\n",
       "      <td>0.959050</td>\n",
       "      <td>0.004823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958225</td>\n",
       "      <td>0.955614</td>\n",
       "      <td>0.960836</td>\n",
       "      <td>0.953003</td>\n",
       "      <td>0.955729</td>\n",
       "      <td>0.950521</td>\n",
       "      <td>0.955729</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.954879</td>\n",
       "      <td>0.003081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950392</td>\n",
       "      <td>0.945170</td>\n",
       "      <td>0.950392</td>\n",
       "      <td>0.950392</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.942708</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.947575</td>\n",
       "      <td>0.002438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.007402</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945170</td>\n",
       "      <td>0.937337</td>\n",
       "      <td>0.947781</td>\n",
       "      <td>0.937337</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.934896</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.941835</td>\n",
       "      <td>0.004225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>11</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947781</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.945170</td>\n",
       "      <td>0.937337</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.934896</td>\n",
       "      <td>0.940104</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.941576</td>\n",
       "      <td>0.003899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.004660</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>13</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942559</td>\n",
       "      <td>0.937337</td>\n",
       "      <td>0.942559</td>\n",
       "      <td>0.937337</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.934896</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.940531</td>\n",
       "      <td>0.004016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.934896</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.940792</td>\n",
       "      <td>0.003883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>17</td>\n",
       "      <td>{'n_neighbors': 17}</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942559</td>\n",
       "      <td>0.937337</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.945170</td>\n",
       "      <td>0.950521</td>\n",
       "      <td>0.934896</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.942708</td>\n",
       "      <td>0.940792</td>\n",
       "      <td>0.004376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.004370</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>19</td>\n",
       "      <td>{'n_neighbors': 19}</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945170</td>\n",
       "      <td>0.932115</td>\n",
       "      <td>0.942559</td>\n",
       "      <td>0.942559</td>\n",
       "      <td>0.950521</td>\n",
       "      <td>0.934896</td>\n",
       "      <td>0.940104</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.941574</td>\n",
       "      <td>0.005254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>21</td>\n",
       "      <td>{'n_neighbors': 21}</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942559</td>\n",
       "      <td>0.934726</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.942559</td>\n",
       "      <td>0.947917</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.942708</td>\n",
       "      <td>0.939488</td>\n",
       "      <td>0.004492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>23</td>\n",
       "      <td>{'n_neighbors': 23}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937337</td>\n",
       "      <td>0.924282</td>\n",
       "      <td>0.937337</td>\n",
       "      <td>0.937337</td>\n",
       "      <td>0.942708</td>\n",
       "      <td>0.934896</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>0.940104</td>\n",
       "      <td>0.936097</td>\n",
       "      <td>0.004864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>25</td>\n",
       "      <td>{'n_neighbors': 25}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932115</td>\n",
       "      <td>0.926893</td>\n",
       "      <td>0.932115</td>\n",
       "      <td>0.934726</td>\n",
       "      <td>0.934896</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.931143</td>\n",
       "      <td>0.004384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.004265</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>27</td>\n",
       "      <td>{'n_neighbors': 27}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929504</td>\n",
       "      <td>0.924282</td>\n",
       "      <td>0.926893</td>\n",
       "      <td>0.934726</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.927751</td>\n",
       "      <td>0.004680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>29</td>\n",
       "      <td>{'n_neighbors': 29}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929504</td>\n",
       "      <td>0.924282</td>\n",
       "      <td>0.929504</td>\n",
       "      <td>0.929504</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.926708</td>\n",
       "      <td>0.003191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.004186      0.000942         0.004138        0.000269   \n",
       "1        0.005145      0.002221         0.006391        0.003672   \n",
       "2        0.003884      0.000021         0.004357        0.000276   \n",
       "3        0.003893      0.000065         0.004295        0.000065   \n",
       "4        0.007033      0.003387         0.007402        0.003725   \n",
       "5        0.004881      0.001995         0.006091        0.003285   \n",
       "6        0.004124      0.000594         0.004660        0.000838   \n",
       "7        0.005012      0.001914         0.006103        0.002981   \n",
       "8        0.004014      0.000159         0.004433        0.000227   \n",
       "9        0.003919      0.000301         0.004370        0.000210   \n",
       "10       0.004020      0.000170         0.004569        0.000225   \n",
       "11       0.004025      0.000262         0.004570        0.000313   \n",
       "12       0.003874      0.000047         0.004382        0.000053   \n",
       "13       0.003803      0.000076         0.004265        0.000081   \n",
       "14       0.003824      0.000099         0.004980        0.001675   \n",
       "\n",
       "   param_n_neighbors               params  split0_test_score  \\\n",
       "0                  1   {'n_neighbors': 1}           0.953488   \n",
       "1                  3   {'n_neighbors': 3}           0.953488   \n",
       "2                  5   {'n_neighbors': 5}           0.953488   \n",
       "3                  7   {'n_neighbors': 7}           0.953488   \n",
       "4                  9   {'n_neighbors': 9}           0.953488   \n",
       "5                 11  {'n_neighbors': 11}           0.953488   \n",
       "6                 13  {'n_neighbors': 13}           0.953488   \n",
       "7                 15  {'n_neighbors': 15}           0.953488   \n",
       "8                 17  {'n_neighbors': 17}           0.953488   \n",
       "9                 19  {'n_neighbors': 19}           0.953488   \n",
       "10                21  {'n_neighbors': 21}           0.953488   \n",
       "11                23  {'n_neighbors': 23}           0.930233   \n",
       "12                25  {'n_neighbors': 25}           0.930233   \n",
       "13                27  {'n_neighbors': 27}           0.930233   \n",
       "14                29  {'n_neighbors': 29}           0.930233   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0            0.953488           0.906977           0.883721  ...   \n",
       "1            0.953488           0.930233           0.860465  ...   \n",
       "2            0.953488           0.930233           0.906977  ...   \n",
       "3            0.930233           0.930233           0.976744  ...   \n",
       "4            0.930233           0.930233           0.953488  ...   \n",
       "5            0.930233           0.930233           0.953488  ...   \n",
       "6            0.930233           0.930233           0.953488  ...   \n",
       "7            0.930233           0.930233           0.953488  ...   \n",
       "8            0.930233           0.930233           0.953488  ...   \n",
       "9            0.930233           0.930233           0.953488  ...   \n",
       "10           0.930233           0.930233           0.930233  ...   \n",
       "11           0.953488           0.930233           0.930233  ...   \n",
       "12           0.930233           0.930233           0.930233  ...   \n",
       "13           0.930233           0.930233           0.906977  ...   \n",
       "14           0.930233           0.930233           0.906977  ...   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             1.000000            1.000000            1.000000   \n",
       "1             0.966057            0.953003            0.960836   \n",
       "2             0.958225            0.955614            0.960836   \n",
       "3             0.950392            0.945170            0.950392   \n",
       "4             0.945170            0.937337            0.947781   \n",
       "5             0.947781            0.939948            0.945170   \n",
       "6             0.942559            0.937337            0.942559   \n",
       "7             0.939948            0.939948            0.939948   \n",
       "8             0.942559            0.937337            0.939948   \n",
       "9             0.945170            0.932115            0.942559   \n",
       "10            0.942559            0.934726            0.939948   \n",
       "11            0.937337            0.924282            0.937337   \n",
       "12            0.932115            0.926893            0.932115   \n",
       "13            0.929504            0.924282            0.926893   \n",
       "14            0.929504            0.924282            0.929504   \n",
       "\n",
       "    split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0             1.000000            1.000000            1.000000   \n",
       "1             0.950392            0.955729            0.955729   \n",
       "2             0.953003            0.955729            0.950521   \n",
       "3             0.950392            0.947917            0.942708   \n",
       "4             0.937337            0.945312            0.934896   \n",
       "5             0.937337            0.945312            0.934896   \n",
       "6             0.937337            0.945312            0.934896   \n",
       "7             0.939948            0.947917            0.934896   \n",
       "8             0.945170            0.950521            0.934896   \n",
       "9             0.942559            0.950521            0.934896   \n",
       "10            0.942559            0.947917            0.932292   \n",
       "11            0.937337            0.942708            0.934896   \n",
       "12            0.934726            0.934896            0.927083   \n",
       "13            0.934726            0.937500            0.921875   \n",
       "14            0.929504            0.929688            0.921875   \n",
       "\n",
       "    split8_train_score  split9_train_score  mean_train_score  std_train_score  \n",
       "0             1.000000            1.000000          1.000000         0.000000  \n",
       "1             0.963542            0.963542          0.959050         0.004823  \n",
       "2             0.955729            0.953125          0.954879         0.003081  \n",
       "3             0.947917            0.947917          0.947575         0.002438  \n",
       "4             0.945312            0.945312          0.941835         0.004225  \n",
       "5             0.940104            0.945312          0.941576         0.003899  \n",
       "6             0.937500            0.947917          0.940531         0.004016  \n",
       "7             0.937500            0.945312          0.940792         0.003883  \n",
       "8             0.937500            0.942708          0.940792         0.004376  \n",
       "9             0.940104            0.945312          0.941574         0.005254  \n",
       "10            0.937500            0.942708          0.939488         0.004492  \n",
       "11            0.932292            0.940104          0.936097         0.004864  \n",
       "12            0.929688            0.929688          0.931143         0.004384  \n",
       "13            0.927083            0.927083          0.927751         0.004680  \n",
       "14            0.927083            0.929688          0.926708         0.003191  \n",
       "\n",
       "[15 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4aea3459e8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results.param_n_neighbors,results.mean_train_score,label = 'Mean_train_score')\n",
    "plt.plot(results.param_n_neighbors,results.mean_test_score,label = 'Mean_test_score')\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('mean_score')\n",
    "plt.title('N_neighbors vs Mean_train/test_score')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested cross validation \n",
    "It means for train and test split as we use cros validation. But it requires lots of time and is not in practice for larger data however for short datasets we can still give it a try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type of cross validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold vs Stratified K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,KFold,StratifiedKFold\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy Classifier is just a random model which predicts randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DummyClassifier('most_frequent') #i.e. it always detects output to be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6274181027790716\n",
      "0.003948679172659169\n"
     ]
    }
   ],
   "source": [
    "stk = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "res = cross_val_score(dm,X,y,cv=stk)\n",
    "print(np.mean(res))\n",
    "print(res.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6273715261605342\n",
      "0.03582507393117649\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5 , shuffle= True)\n",
    "res1 = cross_val_score(dm,X,y,cv=kf)\n",
    "print(np.mean(res1))\n",
    "print(res1.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle must be done to avoid imbalanced dataset problem \n",
    "By Default:\n",
    "\n",
    "1. 5-fold in 0.22 (used to be 3 fold)\n",
    "2. For classification cross-validation is stratified\n",
    "3. train_test_split has stratify option: train_test_split(X, y, stratify=y)\n",
    "4. No shuffle by default!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle K-fold:\n",
    "\n",
    "They are better than k-fold as we know once our data is shuffle we split them into fold and each fold once becomes a test set i.e. no repeation of data in test sets.\n",
    "But here, for each iteration we do shuffling i.e. for iteration one we get our test set then before second iteration we again do shuffle with replacement it may lead to repeation of datas in test set. Here,we chose number of iteration and ratio of test split  so if iteration=1 it works as train_test_split. But this may increase variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit:\n",
      "[0.93567251 0.9005848  0.93567251 0.92982456 0.87719298 0.92982456\n",
      " 0.94152047 0.91812865 0.92982456 0.94152047 0.93567251 0.89473684\n",
      " 0.9005848  0.9122807  0.95321637 0.90643275 0.94736842 0.92397661\n",
      " 0.94736842 0.91812865]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "sh = ShuffleSplit(n_splits=20, train_size=.4, test_size=.3)\n",
    "\n",
    "print(\"ShuffleSplit:\")\n",
    "print(cross_val_score(KNeighborsClassifier(), X, y, cv=sh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It can be used better when we have to only use certain percentage of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated Stratified K-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is more advanced and better k-fold validation. Here for each iteration, stratified k-fold is done several time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepeatedStratifiedKFold:\n",
      "[0.9122807  0.92105263 0.92105263 0.95614035 0.94690265 0.94736842\n",
      " 0.92982456 0.96491228 0.92982456 0.90265487 0.93859649 0.93859649\n",
      " 0.89473684 0.94736842 0.92035398 0.92982456 0.93859649 0.93859649\n",
      " 0.94736842 0.91150442 0.89473684 0.92982456 0.96491228 0.92982456\n",
      " 0.92035398 0.92982456 0.94736842 0.93859649 0.88596491 0.97345133\n",
      " 0.9122807  0.9122807  0.96491228 0.92105263 0.95575221 0.97368421\n",
      " 0.92982456 0.92105263 0.92982456 0.90265487 0.93859649 0.9122807\n",
      " 0.90350877 0.92105263 0.95575221 0.94736842 0.90350877 0.9122807\n",
      " 0.94736842 0.97345133]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "rs = RepeatedStratifiedKFold(n_splits=5, n_repeats=10)\n",
    "\n",
    "print(\"RepeatedStratifiedKFold:\")\n",
    "print(cross_val_score(KNeighborsClassifier(), X, y, cv=rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Group Kfold\n",
    "Suppose we have data of 5 cities pkr,ktm,brt,jhapa,birgunj. Now we have to predict future of people within those city i.e. independent and identically distributed example and can be done as above.\n",
    "\n",
    "But if we have to find for new city say dharan, we don't have data of dharan i.e. model won't predict for dharan as it hasn't seen dharan while on training. In this case GroupKFold is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Series Split\n",
    "Here, data are time  dependent so we can't directly shuffle and chose train and test data as all data are time dependent and if shuffles doesnt provide exact meaning. So, we train using past continous data and try testing by predicting future value. Here, if we dont give max_training data then, test_size will be all data after training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TimeSeriesSplit(5,max_train_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross_validate function\n",
    "It is similar to cross validation score but instead of only score it gives many data such as fit_time ,score_time and scoring metrics selected for both test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "res = cross_validate(KNeighborsClassifier(), X, y, return_train_score=True,\n",
    "                     scoring=[\"accuracy\", \"roc_auc\"])\n",
    "res_df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.112724</td>\n",
       "      <td>0.885965</td>\n",
       "      <td>0.951648</td>\n",
       "      <td>0.945955</td>\n",
       "      <td>0.991538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>0.013457</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.951648</td>\n",
       "      <td>0.952997</td>\n",
       "      <td>0.992355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.011018</td>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.947253</td>\n",
       "      <td>0.981151</td>\n",
       "      <td>0.990733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.011108</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.989680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>0.929204</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.955064</td>\n",
       "      <td>0.992112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy  test_roc_auc  \\\n",
       "0  0.005785    0.112724       0.885965        0.951648      0.945955   \n",
       "1  0.008845    0.013457       0.938596        0.951648      0.952997   \n",
       "2  0.003914    0.011018       0.938596        0.947253      0.981151   \n",
       "3  0.003840    0.011108       0.947368        0.938462      0.962963   \n",
       "4  0.003750    0.010496       0.929204        0.947368      0.955064   \n",
       "\n",
       "   train_roc_auc  \n",
       "0       0.991538  \n",
       "1       0.992355  \n",
       "2       0.990733  \n",
       "3       0.989680  \n",
       "4       0.992112  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
